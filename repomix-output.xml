This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.github/
  workflows/
    deploy.yml
functions/
  src/
    config/
      constants.ts
      templates.ts
    handlers/
      analyzeFoodImage.ts
      backup.ts
      credits.ts
      events.ts
      quickScan.ts
      registerDevice.ts
      sendDailyNudge.ts
      workflow.ts
    middleware/
      auth.ts
      latency.ts
    services/
      backup.ts
      events.ts
      fcm.ts
      firestore.ts
      user.ts
      vision.ts
      workflow.ts
    types/
      behavioral.ts
      index.ts
      visionSchemas.ts
      workflow.ts
    utils/
      errors.ts
      validation.ts
    api.ts
    index.ts
  .eslintrc.js
  package.json
  tsconfig.json
.firebaserc
.gitignore
ai_strategy.md
deferred_deeplink.md
firebase.json
firestore.indexes.json
firestore.rules
future_scope.md
implementation_plan.md
integration.md
README.md
specs.md
storage.rules
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".github/workflows/deploy.yml">
name: Deploy to Firebase

on:
  push:
    branches:
      - main
  workflow_dispatch:

jobs:
  lint-and-build:
    name: Lint and Build
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: functions/package-lock.json

      - name: Install dependencies
        run: npm ci
        working-directory: functions

      - name: Run linter
        run: npm run lint
        working-directory: functions

      - name: Build TypeScript
        run: npm run build
        working-directory: functions

  deploy:
    name: Deploy to Firebase
    needs: lint-and-build
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: functions/package-lock.json

      - name: Install dependencies
        run: npm ci
        working-directory: functions

      - name: Build TypeScript
        run: npm run build
        working-directory: functions

      - name: Deploy to Firebase
        uses: w9jds/firebase-action@master
        with:
          args: deploy --only functions,firestore:rules
        env:
          GCP_SA_KEY: ${{ secrets.FIREBASE_SERVICE_ACCOUNT }}
          PROJECT_ID: ${{ secrets.FIREBASE_PROJECT_ID }}
</file>

<file path="functions/src/config/templates.ts">
import { PersonalizationContext } from "../services/user";

/**
 * Notification template structure.
 * Templates support variable interpolation using {{variableName}} syntax.
 */
export interface NotificationTemplate {
    id: string;
    title: string;
    body: string;
    link: string;
}

/**
 * Central template registry.
 * All notification templates are defined here for consistency and easy updates.
 */
export const TEMPLATES = {
  WEIGHT_REMINDER_V1: {
    id: "weight_reminder_v1",
    title: "Good {{timeOfDay}}, {{displayName}}! ‚öñÔ∏è",
    body: "Time to log your weight.",
    link: "platewise://entry",
  },
  BREAKFAST_V1: {
    id: "breakfast_v1",
    title: "Breakfast time, {{displayName}}! üç≥",
    body: "Had breakfast? Snap a quick photo",
    link: "platewise://food/capture",
  },
  LUNCH_V1: {
    id: "lunch_v1",
    title: "Lunch time, {{displayName}}! ü•ó",
    body: "Capture what you're eating",
    link: "platewise://food/capture",
  },
  SNACKS_V1: {
    id: "snacks_v1",
    title: "Snack check, {{displayName}} üçé",
    body: "Snacking? Log it to stay on track",
    link: "platewise://food/capture",
  },
  DINNER_V1: {
    id: "dinner_v1",
    title: "Dinner time, {{displayName}}! üçΩÔ∏è",
    body: "Don't forget to log your meal",
    link: "platewise://food/capture",
  },
  EVENING_CHECKIN_V1: {
    id: "evening_checkin_v1",
    title: "Daily check-in, {{displayName}} üìä",
    body: "How was your day? Check your progress",
    link: "platewise://dashboard",
  },
} as const;

export type TemplateId = keyof typeof TEMPLATES;

/**
 * Renders a template by replacing placeholders with context values.
 *
 * Supported placeholders:
 * - {{displayName}} - User's display name or "Friend"
 * - {{timeOfDay}} - "morning", "afternoon", or "evening"
 * - {{timezone}} - User's timezone (rarely used in messages)
 *
 * @param template The notification template to render
 * @param context The personalization context with values for placeholders
 * @returns Rendered title and body
 */
export function renderTemplate(
  template: NotificationTemplate,
  context: PersonalizationContext,
): { title: string; body: string } {
  const replacePlaceholders = (text: string): string => {
    return text
      .replace(/\{\{displayName\}\}/g, context.displayName)
      .replace(/\{\{timeOfDay\}\}/g, context.timeOfDay)
      .replace(/\{\{timezone\}\}/g, context.timezone);
  };

  return {
    title: replacePlaceholders(template.title),
    body: replacePlaceholders(template.body),
  };
}

/**
 * Gets a template by its ID.
 * @param templateId The template identifier
 * @returns The template or undefined if not found
 */
export function getTemplate(templateId: TemplateId): NotificationTemplate {
  return TEMPLATES[templateId];
}
</file>

<file path="functions/src/handlers/backup.ts">
import { Request, Response } from "express";
import { logger } from "firebase-functions/v2";
import { saveBackup, loadBackup, getBackupInfo } from "../services/backup";
import { backupSchema, validateInput } from "../utils/validation";
import { handleError, errors } from "../utils/errors";
import { AuthenticatedRequest, verifyAuth } from "../middleware/auth";

/**
 * POST /backup
 * Save user data backup
 */
export async function createBackup(
  req: Request & AuthenticatedRequest,
  res: Response,
): Promise<void> {
  try {
    if (req.method !== "POST") {
      res.status(405).json({ success: false, error: "Method not allowed" });
      return;
    }

    // Verify authentication
    await new Promise<void>((resolve, reject) => {
      verifyAuth(req, res, (err?: unknown) => {
        if (err) reject(err);
        else resolve();
      });
    });

    if (res.headersSent) return;

    const uid = req.uid!; // Safe: verifyAuth ensures uid exists
    logger.info(`Creating backup for user: ${uid}`);

    // Validate input
    const validation = validateInput(backupSchema, req.body);
    if (!validation.success) {
      throw errors.invalidRequest(validation.error);
    }

    await saveBackup(uid, validation.data);

    res.status(200).json({
      success: true,
      message: "Backup saved successfully",
    });
  } catch (error) {
    handleError(error, res);
  }
}

/**
 * POST /restore
 * Restore user data from backup
 */
export async function restoreBackup(
  req: Request & AuthenticatedRequest,
  res: Response,
): Promise<void> {
  try {
    if (req.method !== "POST") {
      res.status(405).json({ success: false, error: "Method not allowed" });
      return;
    }

    // Verify authentication
    await new Promise<void>((resolve, reject) => {
      verifyAuth(req, res, (err?: unknown) => {
        if (err) reject(err);
        else resolve();
      });
    });

    if (res.headersSent) return;

    const uid = req.uid!; // Safe: verifyAuth ensures uid exists
    logger.info(`Restoring backup for user: ${uid}`);

    const backup = await loadBackup(uid);

    res.status(200).json({
      success: true,
      data: backup,
    });
  } catch (error) {
    handleError(error, res);
  }
}

/**
 * GET /backup-status
 * Check if backup exists and get metadata
 */
export async function getBackupStatus(
  req: Request & AuthenticatedRequest,
  res: Response,
): Promise<void> {
  try {
    if (req.method !== "GET") {
      res.status(405).json({ success: false, error: "Method not allowed" });
      return;
    }

    // Verify authentication
    await new Promise<void>((resolve, reject) => {
      verifyAuth(req, res, (err?: unknown) => {
        if (err) reject(err);
        else resolve();
      });
    });

    if (res.headersSent) return;

    const uid = req.uid!; // Safe: verifyAuth ensures uid exists
    const info = await getBackupInfo(uid);

    res.status(200).json({
      success: true,
      ...info,
    });
  } catch (error) {
    handleError(error, res);
  }
}
</file>

<file path="functions/src/handlers/credits.ts">
import { Request, Response } from "express";
import { logger } from "firebase-functions/v2";
import { getCredits, getOrCreateUser } from "../services/user";
import { handleError } from "../utils/errors";
import { AuthenticatedRequest, verifyAuth } from "../middleware/auth";

/**
 * GET /credits
 * Get current user's credit balance
 */
export async function getCreditsHandler(
  req: Request & AuthenticatedRequest,
  res: Response,
): Promise<void> {
  try {
    if (req.method !== "GET") {
      res.status(405).json({ success: false, error: "Method not allowed" });
      return;
    }

    // Verify authentication
    await new Promise<void>((resolve, reject) => {
      verifyAuth(req, res, (err?: unknown) => {
        if (err) reject(err);
        else resolve();
      });
    });

    if (res.headersSent) return;

    const uid = req.uid!; // Safe: verifyAuth ensures uid exists
    logger.info(`Getting credits for user: ${uid}`);

    const credits = await getCredits(uid);

    res.status(200).json({
      success: true,
      credits,
    });
  } catch (error) {
    handleError(error, res);
  }
}

/**
 * GET /user/me
 * Get current user profile including credits
 */
export async function getUserProfile(
  req: Request & AuthenticatedRequest,
  res: Response,
): Promise<void> {
  try {
    if (req.method !== "GET") {
      res.status(405).json({ success: false, error: "Method not allowed" });
      return;
    }

    // Verify authentication
    await new Promise<void>((resolve, reject) => {
      verifyAuth(req, res, (err?: unknown) => {
        if (err) reject(err);
        else resolve();
      });
    });

    if (res.headersSent) return;

    const uid = req.uid!; // Safe: verifyAuth ensures uid exists
    logger.info(`Getting profile for user: ${uid}`);

    const userData = await getOrCreateUser(uid);

    res.status(200).json({
      success: true,
      user: {
        uid,
        aiCredits: userData.aiCredits,
        totalGranted: userData.totalGranted,
        totalUsed: userData.totalUsed,
        createdAt: userData.createdAt.toDate().toISOString(),
        lastActiveAt: userData.lastActiveAt.toDate().toISOString(),
      },
    });
  } catch (error) {
    handleError(error, res);
  }
}
</file>

<file path="functions/src/handlers/events.ts">
/**
 * Events Handler - POST /events endpoint
 *
 * Generic event ingestion with idempotency.
 */
import { Request, Response } from "express";
import { logger } from "firebase-functions/v2";
import { verifyAuth, AuthenticatedRequest } from "../middleware/auth";
import { trackEventTx } from "../services/events";
import { EventRequestSchema, EventPayloads, EventName } from "../types/behavioral";
import { handleError, errors } from "../utils/errors";

/**
 * POST /events
 *
 * Ingests behavioral events with:
 * - Zod schema validation
 * - Firebase Auth verification
 * - Idempotent writes (200 OK for duplicates)
 */
export async function logEvent(req: Request, res: Response): Promise<void> {
  try {
    // Verify auth first
    await new Promise<void>((resolve, reject) => {
      verifyAuth(req, res, (err?: unknown) => {
        if (err) reject(err);
        else resolve();
      });
    });

    const authReq = req as AuthenticatedRequest;
    if (!authReq.uid) {
      throw errors.unauthorized();
    }

    // Validate request body
    const parseResult = EventRequestSchema.safeParse(req.body);
    if (!parseResult.success) {
      const errorMsg = parseResult.error.errors
        .map((e) => `${e.path.join(".")}: ${e.message}`)
        .join(", ");
      throw errors.invalidRequest(errorMsg);
    }

    const { eventId, eventName, timestamp, timezone, sessionId, platform, metadata } = parseResult.data;

    // Validate metadata against event-specific schema
    const metadataSchema = EventPayloads[eventName as EventName];
    if (metadataSchema) {
      const metaResult = metadataSchema.safeParse(metadata);
      if (!metaResult.success) {
        const errorMsg = metaResult.error.errors
          .map((e) => `metadata.${e.path.join(".")}: ${e.message}`)
          .join(", ");
        throw errors.invalidRequest(errorMsg);
      }
    }

    logger.info("Processing event", {
      eventId,
      eventName,
      userId: authReq.uid,
    });

    // Track event transactionally
    const result = await trackEventTx({
      eventId,
      eventName,
      userId: authReq.uid,
      timestamp,
      timezone,
      sessionId,
      platform,
      metadata,
    });

    // Return 200 OK for both new and duplicate events (idempotent success)
    res.status(200).json({
      success: true,
      status: result.status,
      eventId: result.eventId,
    });
  } catch (error) {
    handleError(error, res);
  }
}
</file>

<file path="functions/src/handlers/workflow.ts">
// Workflow handlers for deferred deep linking
import { Request, Response } from "express";
import { handleError, errors } from "../utils/errors";
import { AuthenticatedRequest, verifyAuth } from "../middleware/auth";
import * as workflowService from "../services/workflow";
import { CreateWorkflowRequest, WORKFLOW_TYPES } from "../types/workflow";

/**
 * POST /workflows
 * Creates a new workflow for deferred deep linking
 *
 * Auth: Required
 * Body: CreateWorkflowRequest
 */
export async function createWorkflow(
  req: Request & AuthenticatedRequest,
  res: Response,
): Promise<void> {
  try {
    // Only allow POST
    if (req.method !== "POST") {
      res.status(405).json({
        success: false,
        error: "Method not allowed",
      });
      return;
    }

    // Verify authentication
    await new Promise<void>((resolve, reject) => {
      verifyAuth(req, res, (err?: unknown) => {
        if (err) reject(err);
        else resolve();
      });
    });
    if (res.headersSent) return;

    // Note: Auth verified for rate limiting; uid unused for public workflows
    const body = req.body as CreateWorkflowRequest;

    // Validate required field
    if (!body.type) {
      throw errors.invalidRequest("type is required");
    }

    // Validate workflow type
    if (!WORKFLOW_TYPES.includes(body.type)) {
      throw errors.invalidRequest(
        `Invalid workflow type. Allowed: ${WORKFLOW_TYPES.join(", ")}`,
      );
    }

    // Create workflow
    const result = await workflowService.createWorkflow({
      type: body.type,
      payload: body.payload,
      expiresInHours: body.expiresInHours,
      campaignId: body.campaignId,
      maxResolves: body.maxResolves,
    });

    res.status(200).json({
      success: true,
      workflowId: result.workflowId,
      deepLinkUrl: result.deepLinkUrl,
    });
  } catch (error) {
    handleError(error, res);
  }
}

/**
 * GET /workflows/:id
 * Resolves a workflow by ID
 *
 * Auth: Not required (public workflows)
 *
 * Note: Backend does NOT validate install source.
 * Install attribution is a frontend-only concern.
 * Resolution is allowed from any source by design.
 */
export async function resolveWorkflow(
  req: Request,
  res: Response,
): Promise<void> {
  try {
    const workflowId = req.params.id;

    if (!workflowId) {
      throw errors.invalidRequest("Workflow ID is required");
    }

    const result = await workflowService.resolveWorkflow(workflowId);

    res.status(200).json({
      success: true,
      type: result.type,
      status: result.status,
      payload: result.payload,
      expiresAt: result.expiresAt,
    });
  } catch (error) {
    handleError(error, res);
  }
}

/**
 * POST /workflows/:id/complete
 * Marks a workflow as completed
 *
 * Auth: Not required (public workflows)
 *
 * Idempotent: Calling on already-completed workflow returns success.
 * State guard: Returns 409 if workflow is EXPIRED.
 */
export async function completeWorkflow(
  req: Request,
  res: Response,
): Promise<void> {
  try {
    // Only allow POST
    if (req.method !== "POST") {
      res.status(405).json({
        success: false,
        error: "Method not allowed",
      });
      return;
    }

    const workflowId = req.params.id;

    if (!workflowId) {
      throw errors.invalidRequest("Workflow ID is required");
    }

    const result = await workflowService.completeWorkflow(workflowId);

    res.status(200).json({
      success: true,
      status: result.status,
    });
  } catch (error) {
    handleError(error, res);
  }
}
</file>

<file path="functions/src/middleware/auth.ts">
import { Request, Response, NextFunction } from "express";
import { getAuth } from "firebase-admin/auth";
import { logger } from "firebase-functions/v2";
import { errors } from "../utils/errors";

/**
 * Extended request with authenticated user info
 * uid is optional in type definition because it's added at runtime
 */
export interface AuthenticatedRequest extends Request {
  uid?: string;
  rawBody?: Buffer;
}

/**
 * Middleware to verify Firebase ID token
 * Extracts uid from the token and attaches it to the request
 */
export async function verifyAuth(
  req: Request,
  res: Response,
  next: NextFunction,
): Promise<void> {
  const authHeader = req.headers.authorization;

  if (!authHeader || !authHeader.startsWith("Bearer ")) {
    const error = errors.unauthorized("Missing or invalid Authorization header");
    res.status(error.statusCode).json({
      success: false,
      error: error.message,
      code: error.code,
    });
    return;
  }

  const idToken = authHeader.split("Bearer ")[1];

  try {
    const decodedToken = await getAuth().verifyIdToken(idToken);
    (req as AuthenticatedRequest).uid = decodedToken.uid;
    next();
  } catch (err) {
    logger.warn("Failed to verify auth token", { error: err });
    const error = errors.unauthorized("Invalid or expired token");
    res.status(error.statusCode).json({
      success: false,
      error: error.message,
      code: error.code,
    });
  }
}

/**
 * Optional auth middleware - attaches uid if token is valid, continues if not
 */
export async function optionalAuth(
  req: Request,
  _res: Response,
  next: NextFunction,
): Promise<void> {
  const authHeader = req.headers.authorization;

  if (authHeader && authHeader.startsWith("Bearer ")) {
    const idToken = authHeader.split("Bearer ")[1];
    try {
      const decodedToken = await getAuth().verifyIdToken(idToken);
      (req as AuthenticatedRequest).uid = decodedToken.uid;
    } catch {
      logger.debug("Optional auth failed, continuing without uid");
    }
  }

  next();
}
</file>

<file path="functions/src/middleware/latency.ts">
import { Request, Response, NextFunction } from "express";
import { logger } from "firebase-functions/v2";
import { randomUUID } from "crypto";

/**
 * Extended request with latency tracking
 */
export interface TrackedRequest extends Request {
    requestId: string;
    startTime: number;
}

/**
 * Per-request latency logging with correlation IDs.
 * Logs total request duration on response finish.
 *
 * For stage-level timing within handlers, use:
 *   logger.info('Stage: description', { requestId: req.requestId });
 */
export function latencyLogger(
  req: Request,
  res: Response,
  next: NextFunction,
): void {
  const requestId = randomUUID().slice(0, 8);
  const start = Date.now();

  // Attach to request for downstream logging
  (req as TrackedRequest).requestId = requestId;
  (req as TrackedRequest).startTime = start;

  res.on("finish", () => {
    const duration = Date.now() - start;
    logger.info("Request completed", {
      requestId,
      method: req.method,
      path: req.path,
      status: res.statusCode,
      durationMs: duration,
    });
  });

  next();
}

/**
 * Helper to log stage timing within handlers.
 * Usage: logStage(req, 'OpenAI call start');
 */
export function logStage(req: Request, stage: string, extra?: object): void {
  const tracked = req as TrackedRequest;
  const elapsed = Date.now() - tracked.startTime;
  logger.info(`Stage: ${stage}`, {
    requestId: tracked.requestId,
    elapsedMs: elapsed,
    ...extra,
  });
}
</file>

<file path="functions/src/services/events.ts">
/**
 * Event Service - Transactional Event Tracking
 *
 * Implements idempotent event writes with derived state computation.
 */
import { getFirestore, Timestamp, FieldValue } from "firebase-admin/firestore";
import { logger } from "firebase-functions/v2";
import { randomUUID } from "crypto";
import {
  EventName,
  EventPayloads,
  EventDocument,
  TrackEventResult,
  ROOT_SCHEMA_VERSION,
} from "../types/behavioral";
import { COLLECTIONS } from "../config/constants";

const db = getFirestore();

/**
 * Compute local date string from timestamp and timezone
 */
function getLocalDate(timestamp: Date, timezone: string): string {
  try {
    const formatter = new Intl.DateTimeFormat("en-CA", {
      timeZone: timezone,
      year: "numeric",
      month: "2-digit",
      day: "2-digit",
    });
    return formatter.format(timestamp);
  } catch {
    // Fallback to UTC if timezone is invalid
    return timestamp.toISOString().split("T")[0];
  }
}

/**
 * Compute streak based on date difference
 */
function computeStreak(
  currentStreak: number,
  lastLogDate: string | null,
  newLogDate: string,
): number {
  if (!lastLogDate) {
    return 1; // First log ever
  }

  const last = new Date(lastLogDate);
  const current = new Date(newLogDate);
  const diffDays = Math.floor(
    (current.getTime() - last.getTime()) / (1000 * 60 * 60 * 24),
  );

  if (diffDays === 0) {
    // Same day, streak remains
    return currentStreak;
  } else if (diffDays === 1) {
    // Consecutive day, increment streak
    return currentStreak + 1;
  } else {
    // Gap > 1 day, reset streak
    return 1;
  }
}

interface TrackEventParams {
    eventId: string;
    eventName: EventName;
    userId: string;
    timestamp: string; // ISO 8601
    timezone: string;
    sessionId: string;
    platform: "ios" | "android";
    metadata: Record<string, unknown>;
}

/**
 * Track an event transactionally with idempotency and derived state.
 *
 * Logic Flow (inside transaction):
 * 1. Idempotency Check: Read events/{eventId}. If exists, return duplicate.
 * 2. Read User State: Read users/{userId}.
 * 3. Compute Derived State for WEIGHT_LOGGED.
 * 4. Prepare Writes: set Event doc, update User doc.
 */
export async function trackEventTx(
  params: TrackEventParams,
): Promise<TrackEventResult> {
  const { eventId, eventName, userId, timestamp, timezone, sessionId, platform, metadata } = params;

  // Validate metadata against schema
  const metadataSchema = EventPayloads[eventName];
  if (metadataSchema) {
    const parseResult = metadataSchema.safeParse(metadata);
    if (!parseResult.success) {
      logger.warn("Invalid event metadata", {
        eventName,
        errors: parseResult.error.errors,
      });
      throw new Error(`Invalid metadata for ${eventName}: ${parseResult.error.message}`);
    }
  }

  const eventRef = db.collection(COLLECTIONS.EVENTS).doc(eventId);
  const userRef = db.collection(COLLECTIONS.USERS).doc(userId);

  const eventTimestamp = new Date(timestamp);
  const localDate = getLocalDate(eventTimestamp, timezone);

  const result = await db.runTransaction(async (transaction) => {
    // 1. Idempotency check
    const existingEvent = await transaction.get(eventRef);
    if (existingEvent.exists) {
      logger.info("Duplicate event detected", { eventId });
      return { status: "duplicate" as const, eventId };
    }

    // 2. Read user state
    const userDoc = await transaction.get(userRef);
    const userData = userDoc.exists ? userDoc.data() : null;

    // 3. Compute derived state for WEIGHT_LOGGED
    let streakUpdate: Record<string, unknown> = {};
    if (eventName === EventName.WEIGHT_LOGGED) {
      const currentStreak = userData?.current_streak ?? 0;
      const lastLogDate = userData?.last_log_date ?? null;
      const newStreak = computeStreak(currentStreak, lastLogDate, localDate);

      streakUpdate = {
        current_streak: newStreak,
        last_log_date: localDate,
        total_logs: FieldValue.increment(1),
      };

      logger.info("Streak computed", {
        userId,
        lastLogDate,
        newLogDate: localDate,
        oldStreak: currentStreak,
        newStreak,
      });
    }

    // 4. Prepare event document
    const eventDoc: EventDocument = {
      event_id: eventId,
      user_id: userId,
      event_name: eventName,
      event_timestamp_utc: Timestamp.fromDate(eventTimestamp),
      event_local_date: localDate,
      ingested_at: Timestamp.now(),
      timezone,
      session_id: sessionId,
      platform,
      metadata,
      schema_version: ROOT_SCHEMA_VERSION,
      metadata_version: 1,
    };

    // 5. Write event
    transaction.set(eventRef, eventDoc);

    // 6. Update user document
    if (userDoc.exists) {
      transaction.update(userRef, {
        ...streakUpdate,
        timezone,
        last_active_at: FieldValue.serverTimestamp(),
      });
    } else {
      // Initialize user behavioral state
      transaction.set(
        userRef,
        {
          ...streakUpdate,
          current_streak: streakUpdate.current_streak ?? 0,
          last_log_date: streakUpdate.last_log_date ?? null,
          total_logs: 0,
          timezone,
          last_active_at: FieldValue.serverTimestamp(),
        },
        { merge: true },
      );
    }

    logger.info("Event tracked", { eventId, eventName, userId });
    return { status: "created" as const, eventId };
  });

  return result;
}

/**
 * Helper to generate a new event ID
 */
export function generateEventId(): string {
  return randomUUID();
}

/**
 * Track event without transaction (fire-and-forget for internal use)
 * Used for non-critical events where idempotency is less important.
 */
export async function trackEventAsync(
  params: Omit<TrackEventParams, "eventId" | "sessionId"> & {
        eventId?: string;
        sessionId?: string;
    },
): Promise<void> {
  const eventId = params.eventId ?? generateEventId();
  const sessionId = params.sessionId ?? "server-generated";

  try {
    await trackEventTx({
      ...params,
      eventId,
      sessionId,
    });
  } catch (error) {
    // Log but don't throw - this is fire-and-forget
    logger.error("Failed to track event async", {
      eventId,
      eventName: params.eventName,
      error: error instanceof Error ? error.message : String(error),
    });
  }
}
</file>

<file path="functions/src/services/workflow.ts">
// Workflow service for deferred deep linking
import { db } from "./firestore";
import { ulid } from "ulid";
import { FieldValue, Timestamp } from "firebase-admin/firestore";
import {
  WorkflowDocument,
  WorkflowStatus,
  WorkflowType,
  LogWeightPayload,
  WORKFLOW_ID_REGEX,
  WORKFLOW_TYPES,
  MIN_TTL_HOURS,
  MAX_TTL_HOURS,
  MIN_WEIGHT,
  MAX_WEIGHT,
} from "../types/workflow";
import { ApiError } from "../utils/errors";

// Deep link base URL (Vercel frontend)
const DEEP_LINK_BASE_URL = process.env.DEEP_LINK_BASE_URL ||
    "https://platewise.app";

// Collection reference
const workflowsCollection = db.collection("workflows");

// ============================================================================
// Structured Logging
// ============================================================================

interface WorkflowLogEvent {
    event: string;
    workflowId?: string;
    providedId?: string;
    type?: WorkflowType;
    status?: WorkflowStatus;
    campaignId?: string;
    expiresAt?: string;
    completedAt?: string;
    resolveCount?: number;
    currentStatus?: WorkflowStatus;
    reason?: string;
    timestamp: string;
}

function logWorkflowEvent(event: WorkflowLogEvent): void {
  console.log(JSON.stringify(event));
}

// ============================================================================
// Validation
// ============================================================================

/**
 * Validates workflow ID format (WF_{ULID})
 * Throws 400 if malformed to prevent Firestore injection
 */
export function validateWorkflowId(id: string): void {
  if (!WORKFLOW_ID_REGEX.test(id)) {
    logWorkflowEvent({
      event: "workflow_invalid_id",
      providedId: id,
      reason: "Malformed workflow ID format",
      timestamp: new Date().toISOString(),
    });
    throw new ApiError(400, "Invalid workflow ID format", "INVALID_WORKFLOW_ID");
  }
}

/**
 * Validates workflow type against allowed types
 */
export function validateWorkflowType(type: string): asserts type is WorkflowType {
  if (!WORKFLOW_TYPES.includes(type as WorkflowType)) {
    throw new ApiError(
      400,
      `Invalid workflow type. Allowed: ${WORKFLOW_TYPES.join(", ")}`,
      "INVALID_WORKFLOW_TYPE",
    );
  }
}

/**
 * Validates TTL is within bounds [MIN_TTL_HOURS, MAX_TTL_HOURS]
 */
export function validateTTL(hours: number): void {
  if (hours < MIN_TTL_HOURS || hours > MAX_TTL_HOURS) {
    throw new ApiError(
      400,
      `TTL must be between ${MIN_TTL_HOURS} and ${MAX_TTL_HOURS} hours`,
      "INVALID_TTL",
    );
  }
}

/**
 * Validates payload based on workflow type
 */
export function validatePayload(
  type: WorkflowType,
  payload: LogWeightPayload | undefined,
): LogWeightPayload {
  const validatedPayload: LogWeightPayload = { ...payload };

  if (type === "LOG_WEIGHT") {
    if (
      validatedPayload.suggestedWeight !== undefined &&
            (validatedPayload.suggestedWeight < MIN_WEIGHT ||
                validatedPayload.suggestedWeight > MAX_WEIGHT)
    ) {
      throw new ApiError(
        400,
        `suggestedWeight must be between ${MIN_WEIGHT} and ${MAX_WEIGHT}`,
        "INVALID_PAYLOAD",
      );
    }
  }

  return validatedPayload;
}

// ============================================================================
// Service Functions
// ============================================================================

/**
 * Generates a new workflow ID with ULID
 */
function generateWorkflowId(): string {
  return `WF_${ulid()}`;
}

/**
 * Computes the effective status considering expiry
 * Does NOT mutate the document - expiry is computed, not persisted
 */
function computeStatus(workflow: WorkflowDocument): WorkflowStatus {
  if (workflow.status === "COMPLETED") {
    return "COMPLETED";
  }

  const now = Timestamp.now();
  if (workflow.expiresAt.toMillis() < now.toMillis()) {
    return "EXPIRED";
  }

  return "ACTIVE";
}

/**
 * Creates a new workflow
 */
export async function createWorkflow(params: {
    type: WorkflowType;
    payload?: LogWeightPayload;
    expiresInHours?: number;
    campaignId?: string;
    maxResolves?: number;
}): Promise<{ workflowId: string; deepLinkUrl: string }> {
  const {
    type,
    payload,
    expiresInHours = 48,
    campaignId,
    maxResolves,
  } = params;

  // Validate inputs
  validateWorkflowType(type);
  validateTTL(expiresInHours);
  const validatedPayload = validatePayload(type, payload);

  // Generate ID and timestamps
  const workflowId = generateWorkflowId();
  const now = Timestamp.now();
  const expiresAt = Timestamp.fromMillis(
    now.toMillis() + expiresInHours * 60 * 60 * 1000,
  );

  // Create workflow document
  // userId is null for public workflows (current implementation)
  const workflowDoc: WorkflowDocument = {
    id: workflowId,
    type,
    status: "ACTIVE",
    payload: validatedPayload,
    userId: null, // Public workflows for now
    campaignId,
    createdAt: now,
    expiresAt,
    maxResolves,
    metadata: {
      clickCount: 0,
      resolveCount: 0,
    },
  };

  // Store in Firestore
  await workflowsCollection.doc(workflowId).set(workflowDoc);

  // Build deep link URL
  const deepLinkUrl = `${DEEP_LINK_BASE_URL}/wf/${workflowId}`;

  // Log creation
  logWorkflowEvent({
    event: "workflow_created",
    workflowId,
    type,
    campaignId,
    expiresAt: expiresAt.toDate().toISOString(),
    timestamp: new Date().toISOString(),
  });

  return { workflowId, deepLinkUrl };
}

/**
 * Resolves a workflow by ID
 * Returns computed status (EXPIRED if past TTL, without persisting)
 */
export async function resolveWorkflow(workflowId: string): Promise<{
    type: WorkflowType;
    status: WorkflowStatus;
    payload: LogWeightPayload;
    expiresAt: string;
}> {
  // Validate ID format
  validateWorkflowId(workflowId);

  // Fetch document
  const docRef = workflowsCollection.doc(workflowId);
  const docSnap = await docRef.get();

  if (!docSnap.exists) {
    throw new ApiError(404, "Workflow not found", "WORKFLOW_NOT_FOUND");
  }

  const workflow = docSnap.data() as WorkflowDocument;

  // Compute effective status (lazy expiry - no persistence)
  const computedStatus = computeStatus(workflow);

  // Increment resolve counter atomically
  await docRef.update({
    "metadata.resolveCount": FieldValue.increment(1),
    "metadata.lastResolvedAt": Timestamp.now(),
  });

  // Log based on status
  if (computedStatus === "EXPIRED") {
    logWorkflowEvent({
      event: "workflow_expired_access",
      workflowId,
      expiresAt: workflow.expiresAt.toDate().toISOString(),
      timestamp: new Date().toISOString(),
    });
  } else {
    logWorkflowEvent({
      event: "workflow_resolved",
      workflowId,
      status: computedStatus,
      resolveCount: (workflow.metadata.resolveCount || 0) + 1,
      timestamp: new Date().toISOString(),
    });
  }

  return {
    type: workflow.type,
    status: computedStatus,
    payload: workflow.payload,
    expiresAt: workflow.expiresAt.toDate().toISOString(),
  };
}

/**
 * Completes a workflow (atomic transaction with state guard)
 *
 * State transitions allowed:
 * - ACTIVE ‚Üí COMPLETED ‚úì
 *
 * State transitions forbidden:
 * - COMPLETED ‚Üí ACTIVE ‚ùå
 * - EXPIRED ‚Üí ACTIVE ‚ùå
 * - EXPIRED ‚Üí COMPLETED ‚ùå
 */
export async function completeWorkflow(
  workflowId: string,
): Promise<{ status: "COMPLETED" }> {
  // Validate ID format
  validateWorkflowId(workflowId);

  const docRef = workflowsCollection.doc(workflowId);

  await db.runTransaction(async (transaction) => {
    const docSnap = await transaction.get(docRef);

    if (!docSnap.exists) {
      throw new ApiError(404, "Workflow not found", "WORKFLOW_NOT_FOUND");
    }

    const workflow = docSnap.data() as WorkflowDocument;
    const computedStatus = computeStatus(workflow);

    // State guard: only ACTIVE workflows can be completed
    // Idempotent: if already COMPLETED, return success
    if (computedStatus === "COMPLETED") {
      logWorkflowEvent({
        event: "workflow_completed",
        workflowId,
        completedAt: workflow.completedAt?.toDate().toISOString() || "unknown",
        timestamp: new Date().toISOString(),
      });
      return; // Already completed, idempotent success
    }

    // Forbidden: cannot complete expired workflows
    if (computedStatus === "EXPIRED") {
      logWorkflowEvent({
        event: "workflow_illegal_transition",
        workflowId,
        currentStatus: "EXPIRED",
        timestamp: new Date().toISOString(),
      });
      throw new ApiError(
        409,
        "Cannot complete expired workflow",
        "WORKFLOW_EXPIRED",
      );
    }

    // Transition to COMPLETED
    const now = Timestamp.now();
    transaction.update(docRef, {
      status: "COMPLETED",
      completedAt: now,
    });

    logWorkflowEvent({
      event: "workflow_completed",
      workflowId,
      completedAt: now.toDate().toISOString(),
      timestamp: new Date().toISOString(),
    });
  });

  return { status: "COMPLETED" };
}
</file>

<file path="functions/src/types/behavioral.ts">
/**
 * Behavioral Types and Schemas for Event-Sourced Architecture
 * @version 1.0.0
 */
import { z } from "zod";

// Root schema version enforced on all events
export const ROOT_SCHEMA_VERSION = 1;

/**
 * Event Names - all trackable user behaviors
 */
export enum EventName {
  DEVICE_REGISTERED = "DEVICE_REGISTERED",
  WEIGHT_LOGGED = "WEIGHT_LOGGED",
  FOOD_ANALYZED = "FOOD_ANALYZED",
  NOTIFICATION_DELIVERED = "NOTIFICATION_DELIVERED",
  NOTIFICATION_RECEIVED = "NOTIFICATION_RECEIVED",
  NOTIFICATION_OPENED = "NOTIFICATION_OPENED",
  INTENT_CAPTURED = "INTENT_CAPTURED",
  INTENT_CLOSED = "INTENT_CLOSED",
}

/**
 * Event Metadata Schemas
 */
export const DeviceRegisteredMetadata = z.object({
  timezone: z.string().min(1),
  platform: z.enum(["ios", "android"]),
  app_version: z.string().optional(),
});

export const WeightLoggedMetadata = z.object({
  weight_value: z.number().positive(),
  unit: z.enum(["kg", "lbs"]).default("kg"),
  source: z.enum(["manual", "auto"]).default("manual"),
});

export const FoodAnalyzedMetadata = z.object({
  success: z.boolean(),
  food_detected: z.boolean(),
  credits_remaining: z.number().int().min(0),
  latency_ms: z.number().int().min(0),
});

export const NotificationDeliveredMetadata = z.object({
  notification_id: z.string().uuid(),
  notification_type: z.string().min(1),
  delivery_status: z.enum(["success", "failed"]),
  error_message: z.string().optional(),
});

export const NotificationReceivedMetadata = z.object({
  notification_id: z.string().uuid(),
  received_at: z.string().datetime(),
});

export const NotificationOpenedMetadata = z.object({
  notification_id: z.string().uuid(),
  opened_at: z.string().datetime(),
});

export const IntentCapturedMetadata = z.object({
  intent_type: z.string().min(1),
  expected_duration: z.number().int().min(0), // in minutes
});

export const IntentClosedMetadata = z.object({
  intent_type: z.string().min(1),
  outcome: z.enum(["completed", "abandoned", "expired"]),
  actual_duration: z.number().int().min(0), // in minutes
  expected_duration: z.number().int().min(0), // in minutes
});

/**
 * Event Payloads mapping - used for runtime validation
 */
export const EventPayloads = {
  [EventName.DEVICE_REGISTERED]: DeviceRegisteredMetadata,
  [EventName.WEIGHT_LOGGED]: WeightLoggedMetadata,
  [EventName.FOOD_ANALYZED]: FoodAnalyzedMetadata,
  [EventName.NOTIFICATION_DELIVERED]: NotificationDeliveredMetadata,
  [EventName.NOTIFICATION_RECEIVED]: NotificationReceivedMetadata,
  [EventName.NOTIFICATION_OPENED]: NotificationOpenedMetadata,
  [EventName.INTENT_CAPTURED]: IntentCapturedMetadata,
  [EventName.INTENT_CLOSED]: IntentClosedMetadata,
} as const;

/**
 * Base Event Request Schema (from client)
 */
export const EventRequestSchema = z.object({
  eventId: z.string().uuid(),
  eventName: z.nativeEnum(EventName),
  timestamp: z.string().datetime(),
  timezone: z.string().min(1),
  sessionId: z.string().uuid(),
  platform: z.enum(["ios", "android"]),
  metadata: z.record(z.unknown()),
});

export type EventRequest = z.infer<typeof EventRequestSchema>;

/**
 * Internal Event Document (stored in Firestore)
 */
export interface EventDocument {
  event_id: string;
  user_id: string;
  event_name: EventName;
  event_timestamp_utc: FirebaseFirestore.Timestamp;
  event_local_date: string; // YYYY-MM-DD in user's timezone
  ingested_at: FirebaseFirestore.Timestamp;
  timezone: string;
  session_id: string;
  platform: "ios" | "android";
  metadata: Record<string, unknown>;
  schema_version: number;
  metadata_version: number;
}

/**
 * User behavioral state (stored on user document)
 */
export interface UserBehavioralState {
  current_streak: number;
  last_log_date: string | null; // YYYY-MM-DD
  timezone: string;
  total_logs: number;
  last_active_at: FirebaseFirestore.Timestamp;
}

/**
 * Track event result
 */
export interface TrackEventResult {
  status: "created" | "duplicate";
  eventId: string;
}

// Type inference helpers
export type DeviceRegisteredMeta = z.infer<typeof DeviceRegisteredMetadata>;
export type WeightLoggedMeta = z.infer<typeof WeightLoggedMetadata>;
export type FoodAnalyzedMeta = z.infer<typeof FoodAnalyzedMetadata>;
export type NotificationDeliveredMeta = z.infer<typeof NotificationDeliveredMetadata>;
export type NotificationReceivedMeta = z.infer<typeof NotificationReceivedMetadata>;
export type NotificationOpenedMeta = z.infer<typeof NotificationOpenedMetadata>;
export type IntentCapturedMeta = z.infer<typeof IntentCapturedMetadata>;
export type IntentClosedMeta = z.infer<typeof IntentClosedMetadata>;
</file>

<file path="functions/src/types/workflow.ts">
// Workflow types for deferred deep linking
import { Timestamp } from "firebase-admin/firestore";

// Workflow ID validation regex (ULID with WF_ prefix)
export const WORKFLOW_ID_REGEX = /^WF_[0-9A-HJKMNP-TV-Z]{26}$/;

// TTL bounds
export const MIN_TTL_HOURS = 1;
export const MAX_TTL_HOURS = 72;

// Payload weight bounds
export const MIN_WEIGHT = 20;
export const MAX_WEIGHT = 300;

// Allowed workflow types
export const WORKFLOW_TYPES = ["LOG_WEIGHT"] as const;
export type WorkflowType = (typeof WORKFLOW_TYPES)[number];

// Workflow status
export type WorkflowStatus = "ACTIVE" | "COMPLETED" | "EXPIRED";

// Per-type payload schemas
export interface LogWeightPayload {
    suggestedWeight?: number; // Validated: 20-300
    source?: string;
}

// Workflow document stored in Firestore
export interface WorkflowDocument {
    id: string; // WF_{ULID}
    type: WorkflowType;
    status: WorkflowStatus;
    payload: LogWeightPayload;
    userId: string | null; // null = public workflow
    campaignId?: string;
    createdAt: Timestamp;
    expiresAt: Timestamp;
    completedAt?: Timestamp;
    maxResolves?: number; // Optional limit for campaign protection
    metadata: {
        clickCount: number;
        resolveCount: number;
        lastResolvedAt?: Timestamp;
    };
}

// Create workflow request
export interface CreateWorkflowRequest {
    type: WorkflowType;
    payload?: LogWeightPayload;
    expiresInHours?: number; // Default: 48, Min: 1, Max: 72
    campaignId?: string;
    maxResolves?: number;
}

// Create workflow response
export interface CreateWorkflowResponse {
    success: true;
    workflowId: string;
    deepLinkUrl: string;
}

// Resolve workflow response
export interface ResolveWorkflowResponse {
    success: true;
    type: WorkflowType;
    status: WorkflowStatus;
    payload: LogWeightPayload;
    expiresAt: string; // ISO 8601
}

// Complete workflow response
export interface CompleteWorkflowResponse {
    success: true;
    status: "COMPLETED";
}
</file>

<file path="functions/.eslintrc.js">
module.exports = {
    root: true,
    env: {
        es2022: true,
        node: true,
    },
    extends: [
        "eslint:recommended",
        "plugin:import/errors",
        "plugin:import/warnings",
        "plugin:import/typescript",
        "google",
        "plugin:@typescript-eslint/recommended",
    ],
    parser: "@typescript-eslint/parser",
    parserOptions: {
        project: ["tsconfig.json"],
        sourceType: "module",
    },
    ignorePatterns: [
        "/lib/**/*",
        "/node_modules/**/*",
    ],
    plugins: [
        "@typescript-eslint",
        "import",
    ],
    rules: {
        "quotes": ["error", "double"],
        "import/no-unresolved": 0,
        "indent": ["error", 2],
        "max-len": ["error", { "code": 120 }],
        "object-curly-spacing": ["error", "always"],
        "require-jsdoc": 0,
        "valid-jsdoc": 0,
    },
};
</file>

<file path="functions/tsconfig.json">
{
    "compilerOptions": {
        "module": "commonjs",
        "noImplicitReturns": true,
        "noUnusedLocals": true,
        "outDir": "lib",
        "sourceMap": true,
        "strict": true,
        "target": "ES2022",
        "skipLibCheck": true,
        "esModuleInterop": true,
        "resolveJsonModule": true,
        "moduleResolution": "node",
        "declaration": true,
        "declarationMap": true
    },
    "compileOnSave": true,
    "include": [
        "src"
    ]
}
</file>

<file path=".firebaserc">
{
  "projects": {
    "default": "platewise-b8995"
  }
}
</file>

<file path="ai_strategy.md">
# AI Observability & Evaluation Strategy

## 1. Observability: "What is happening right now?"

Observability goes beyond simple logging. It answers questions like *"Why did that request cost $0.05?"* or *"Why is the model hallucinating hot dogs as carrots?"*.

### A. The "Black Box" Recorder
We are currently logging inputs (Image Hash) and outputs (Parsed JSON). We need to enrich this.

**Action Items:**
1.  **Capture Token Usage**: Extract `response.usage` (prompt_tokens, completion_tokens) from OpenAI responses.
    *   *Why:* To calculate exact COGS (Cost of Goods Sold) per image analysis.
2.  **Trace ID Propagation**: Ensure a single `traceId` follows the request from the Client -> API -> Stage 1 -> Stage 2 -> Firestore.
3.  **Model Configuration Snapshot**: Store the exact params used (temperature, max_tokens, prompt_version) alongside the result. You are already doing this with `promptVersion`‚Äîexcellent.

### B. The Feedback Loop (The "Golden Signal")
The most valuable signal is **User Correction**.
If the AI predicts "150g Chicken Breast" and the user changes it to "200g Steak", that is a high-quality training example.

**Implementation Approach:**
1.  **Link Analysis to Entry**: When the user saves a meal, pass the `FoodAnalysisRecord.id` that generated the data.
2.  **The "Act vs. Predict" Diff**: Trigger a background function on meal save:
    *   **Predicted**: { food: "Chicken", calories: 200 } (from `FoodAnalysisRecord`)
    *   **Actual**: { food: "Steak", calories: 450 } (from `MealLog`)
    *   **Metric**: Calculate `Error %` or `Semantic Distance`.
3.  **Flagging**: If `Error % > 50%`, flag the image for manual review (to be added to your Golden Dataset).

---

## 2. Evaluations (Evals): "Is it getting better?"

Never deploy a prompt change without running Evals. It protects you from regression (e.g., you fix "Pizza detection" but break "Salad detection").

### A. The "Golden Dataset"
You need a "Truth Set".

**Structure:**
*   Folder: `evals/dataset/`
*   Content:
    *   `pizza_01.jpg` -> `pizza_01.json` (Expected: "Pizza", ~300kcal)
    *   `salad_bowl.jpg` -> `salad_bowl.json` (Expected: "Mixed Greens", ~50kcal)
*   **Size**: Start with 20 diverse images. Aim for 50.

### B. Automated Eval Pipeline (CI/CD for AI)
Create a script (e.g., `npm run eval`) that:
1.  Iterates through your Golden Dataset.
2.  Runs your *current* `vision.ts` logic against each image.
3.  **Scores the result** against the `.json` truth file.

**Scoring Metrics:**
1.  **Hit Rate (Classification)**: Did it identify the "Pizza"? (Yes/No)
    *   *Implementation*: `string similarity` check or `LLM-as-a-Judge` ("Does 'Margherita Pie' mean 'Pizza'?").
2.  **MAE (Mean Absolute Error) for Calories**: `Abs(Predicted - Actual)`.
    *   *Goal*: Minimize this number across the dataset.

### C. LLM-as-a-Judge
Instead of writing complex Regex to compare "Steak" vs "Beef Steak", use a cheap LLM (gpt-4o-mini) to grade the response.

**Prompt for Judge:**
> "Ground truth is 'Grilled Chicken Salad'. Model predicted 'Chicken Caesar Salad'. On a scale of 0-1, how accurate is this? 1 = Correct, 0 = Wrong."

---

## 3. Implementation Roadmap

### Phase 1: Passive Observation (Low Effort)
- [ ] Update `vision.ts` to log token usage and costs.
- [ ] Add `parentAnalysisId` to your `FoodLog` schema to link saved meals back to AI predictions.

### Phase 2: dataset Accumulation
- [ ] Create a script to query Firestore for "High Correction" events (where user changed >50% of values).
- [ ] Download these images + user's "Actual" data to form your **Golden Dataset**.

### Phase 3: Automated Evals
- [ ] Write the `evals/run.ts` script.
- [ ] Run this script before every prompt edit.
</file>

<file path="deferred_deeplink.md">
Good. Now we stop philosophizing and write something you could hand to an engineer.

We‚Äôll define a **backend technical specification** for:

> Workflow-driven deferred deep linking
> Using Firebase (Functions + Firestore)
> Frontend hosted on Vercel

No hand-waving. Concrete contracts.

---

# 1. System Overview

## Objective

Implement a server-authoritative workflow system that:

* Generates workflow IDs
* Resolves workflow state after install
* Enforces TTL and ownership
* Supports deferred deep linking
* Is idempotent
* Is auditable

All routing decisions are driven by backend state.

---

# 2. Data Model (Firestore)

## 2.1 Collection: `workflows`

**Path**

```
/workflows/{workflowId}
```

### Schema

```ts
interface Workflow {
  id: string                // WF_xxx (doc id)
  type: string              // LOG_WEIGHT | START_CHALLENGE | etc
  status: "ACTIVE" | "COMPLETED" | "EXPIRED"
  
  payload: {
    // Arbitrary JSON
    suggestedWeight?: number
    source?: string
  }

  userId: string | null     // null = public workflow
  campaignId?: string

  createdAt: Timestamp
  expiresAt: Timestamp

  completedAt?: Timestamp

  metadata: {
    clickCount: number
    resolveCount: number
    lastResolvedAt?: Timestamp
  }
}
```

---

## 2.2 Collection: `workflowClicks` (Optional but Recommended)

Used for attribution + debugging.

```
/workflowClicks/{clickId}
```

```ts
{
  workflowId: string
  createdAt: Timestamp
  ipHash: string
  userAgent: string
  installReferrerToken?: string
}
```

---

# 3. Workflow ID Format

Format:

```
WF_{ULID}
```

Use ULID (time-sortable unique ID) instead of random UUID.

Reason:

* Easier debugging
* Ordered by creation time
* Safer for analytics queries

---

# 4. Firebase Functions (HTTP + Callable)

All endpoints validate input strictly.

---

# 4.1 Create Workflow

### Endpoint

```
POST /api/workflows
```

### Auth

Required (Firebase Auth)

### Request

```json
{
  "type": "LOG_WEIGHT",
  "payload": {
    "suggestedWeight": 72.5
  },
  "expiresInHours": 48,
  "campaignId": "JAN_CAMPAIGN"
}
```

### Logic

1. Validate type against allowed enum.
2. Enforce max TTL (e.g., 72 hours).
3. Generate ULID.
4. Store workflow doc.
5. Return deep link URL.

### Response

```json
{
  "workflowId": "WF_01HRX...",
  "deepLinkUrl": "https://platewise.app/wf/WF_01HRX..."
}
```

---

# 4.2 Resolve Workflow

### Endpoint

```
GET /api/workflows/{workflowId}
```

### Auth

Optional (depends on workflow type)

### Logic

1. Fetch document.
2. If not found ‚Üí 404.
3. If status = COMPLETED ‚Üí return COMPLETED.
4. If expiresAt < now ‚Üí mark EXPIRED, return EXPIRED.
5. If userId != null and user not authenticated ‚Üí 401.
6. If userId != null and mismatch ‚Üí 403.
7. Increment resolveCount.
8. Return workflow payload.

### Response

```json
{
  "type": "LOG_WEIGHT",
  "status": "ACTIVE",
  "payload": {
    "suggestedWeight": 72.5
  },
  "expiresAt": "2026-02-05T00:00:00Z"
}
```

---

# 4.3 Complete Workflow

### Endpoint

```
POST /api/workflows/{workflowId}/complete
```

### Auth

Required

### Logic

Atomic Firestore transaction:

1. Fetch workflow.
2. If status != ACTIVE ‚Üí return idempotent success.
3. Update:

   * status = COMPLETED
   * completedAt = now
4. Commit.

### Response

```json
{
  "status": "COMPLETED"
}
```

Idempotent by design.

---

# 5. Deferred Deep Link Resolution (Android)

## Install Referrer Handling

Frontend retrieves:

```
workflow_id=WF_123
```

Frontend then calls:

```
GET /api/workflows/WF_123
```

Backend remains authoritative.

No special backend endpoint required.

---

# 6. Web Link Handling (Vercel)

You must create:

```
/wf/[workflowId]
```

### Behavior

Server-side:

1. Validate workflowId format.
2. Log click (optional).
3. Detect user-agent.
4. If Android:

   * Redirect to Play Store with referrer:

     ```
     referrer=workflow_id=WF_123
     ```
5. If iOS:

   * Redirect to App Store (no native referrer equivalent).
6. If desktop:

   * Show fallback page with QR.

---

# 7. Expiry Enforcement

Two layers:

## Lazy Expiry

When resolving, if expired:

* Mark EXPIRED
* Return EXPIRED

## Scheduled Cleanup (Optional)

Firebase Scheduled Function runs daily:

* Query workflows where:

  * status = ACTIVE
  * expiresAt < now
* Mark as EXPIRED

---

# 8. Retry Strategy (Backend)

Backend should be stateless.

Client handles retry logic.

However:

* Ensure GET /workflow is idempotent.
* No side effects except metadata counters.
* Counters should use atomic increment.

---

# 9. Security Rules (Firestore)

Block direct client writes.

Firestore Rules:

```js
match /workflows/{id} {
  allow read: if false;
  allow write: if false;
}
```

All operations must go through Functions.

---

# 10. Rate Limiting

Protect resolve endpoint.

Option 1:

* Firebase App Check

Option 2:

* Track IP + throttle > 30 requests/min per workflow

Prevents brute-force enumeration.

---

# 11. Observability

Log structured events:

* workflow_created
* workflow_resolved
* workflow_completed
* workflow_expired

Store in BigQuery or analytics system.

---

# 12. Failure Modes

## Case 1 ‚Äî Workflow Not Found

Return 404.
Frontend shows generic fallback.

## Case 2 ‚Äî Expired

Return EXPIRED.
Frontend navigates to home.

## Case 3 ‚Äî Already Completed

Return COMPLETED.
Frontend navigates to trends.

---

# 13. Idempotency Rules

* Resolve = safe
* Complete = transactional
* Duplicate complete calls = safe
* Expiry auto-update = safe

System must tolerate:

* Multiple app launches
* Network retries
* Double clicks
* App restarts

---

# 14. Non-Goals

Backend does NOT:

* Navigate screens
* Trust install referrer blindly
* Auto-complete workflows
* Store sensitive client state

---

# 15. Minimal Deployment Stack

Firebase:

* Firestore
* Cloud Functions (HTTP)
* Scheduled Functions
* App Check

Vercel:

* Next.js route handler for `/wf/[workflowId]`

---

# What You Now Have

Not ‚Äúdeferred deep link.‚Äù

You have:

A deterministic workflow execution backend with:

* TTL
* Ownership
* Idempotency
* State transitions
* Attribution hooks
* Platform-agnostic resolution

When you later move to fintech, you change:

```
type = LOG_WEIGHT
```

to

```
type = BBPS_PAYMENT
```

And the backend shape barely changes.

That‚Äôs the point.

Architecture is reusable when it‚Äôs state-driven, not screen-driven.

If you want, next we can define the exact Next.js Vercel handler spec and Android install referrer parsing spec in similar detail.
</file>

<file path="future_scope.md">
# Future Scope: Deferred Deep Links

Deferred features for rate limiting, scheduled cleanup, iOS support, and analytics.

---

## Rate Limiting

### Option 1: Firebase App Check

Add device attestation to prevent abuse.

```typescript
// Enable App Check in your Firebase console
// Frontend: Initialize App Check with reCAPTCHA or device attestation
import { initializeAppCheck, ReCaptchaV3Provider } from "firebase/app-check";

initializeAppCheck(app, {
  provider: new ReCaptchaV3Provider("your-recaptcha-site-key"),
  isTokenAutoRefreshEnabled: true
});
```

Backend verification:
```typescript
import { getAppCheck } from "firebase-admin/app-check";

async function verifyAppCheck(req: Request) {
  const appCheckToken = req.headers["x-firebase-appcheck"];
  if (appCheckToken) {
    try {
      await getAppCheck().verifyToken(appCheckToken);
      return true;
    } catch {
      return false;
    }
  }
  return false;
}
```

### Option 2: IP-Based Throttling

Track IP hash on resolve and throttle > 30 requests/min per workflow.

```typescript
// Add to resolve workflow
const ipHash = crypto.createHash('sha256')
  .update(req.ip || '')
  .digest('hex')
  .substring(0, 16);

console.log(JSON.stringify({
  event: "workflow_resolved",
  workflowId,
  ipHash,
  timestamp: new Date().toISOString()
}));
```

### Option 3: Cloud Armor (GCP)

If publicly exposed, add Cloud Armor WAF rules for:
- Geographic restrictions
- Rate limiting by IP
- Bot protection

---

## Scheduled Expiry Cleanup

Run daily at 2 AM IST to clean up expired workflows:

```typescript
// functions/src/scheduled/workflowCleanup.ts
import * as functions from "firebase-functions/v2/scheduler";
import { db } from "../services/firestore";
import { Timestamp } from "firebase-admin/firestore";

export const cleanupExpiredWorkflows = functions.onSchedule(
  {
    schedule: "0 2 * * *",  // Daily at 2 AM
    timeZone: "Asia/Kolkata",
  },
  async () => {
    const now = Timestamp.now();
    const batch = db.batch();
    let count = 0;

    const expiredDocs = await db.collection("workflows")
      .where("status", "==", "ACTIVE")
      .where("expiresAt", "<", now)
      .limit(500)
      .get();

    expiredDocs.forEach((doc) => {
      batch.update(doc.ref, { status: "EXPIRED" });
      count++;
    });

    if (count > 0) {
      await batch.commit();
      console.log(JSON.stringify({
        event: "workflow_cleanup_completed",
        expiredCount: count,
        timestamp: now.toDate().toISOString()
      }));
    }
  }
);
```

---

## iOS Deferred Deep Linking

iOS App Store doesn't support install referrers. Alternatives:

### Option A: Fingerprinting (Not Recommended)

Match IP + User Agent between web click and app launch.
- Privacy concerns
- Low accuracy
- GDPR implications

### Option B: Clipboard-Based

1. Copy workflow ID to clipboard before redirect
2. App reads clipboard on first launch
3. Prompt user for permission (iOS 14+)

```swift
// After redirect, copy to clipboard
UIPasteboard.general.string = "WF_01HRX..."

// In app, after permission
if let workflowId = UIPasteboard.general.string,
   workflowId.hasPrefix("WF_") {
    resolveWorkflow(workflowId)
}
```

### Option C: Skip iOS (MVP)

Focus on Android. iOS users get normal install flow.

---

## Distributed Counters (High Traffic)

For campaigns exceeding 1 write/second per workflow:

```typescript
// Create sharded counter
const SHARD_COUNT = 10;

async function incrementResolveCount(workflowId: string) {
  const shardId = Math.floor(Math.random() * SHARD_COUNT);
  const shardRef = db.doc(`workflowStats/${workflowId}/shards/${shardId}`);
  
  await shardRef.set({
    count: FieldValue.increment(1)
  }, { merge: true });
}

async function getResolveCount(workflowId: string): Promise<number> {
  const shards = await db.collection(`workflowStats/${workflowId}/shards`).get();
  return shards.docs.reduce((total, doc) => total + (doc.data().count || 0), 0);
}
```

---

## BigQuery Analytics

Export workflow events for analytics:

1. Enable Firestore to BigQuery extension
2. Create materialized views for:
   - Campaign performance
   - Conversion rates
   - TTL optimization

```sql
-- Example: Campaign conversion rate
SELECT
  campaignId,
  COUNT(*) as total_created,
  COUNTIF(status = 'COMPLETED') as completed,
  COUNTIF(status = 'EXPIRED') as expired,
  SAFE_DIVIDE(COUNTIF(status = 'COMPLETED'), COUNT(*)) as conversion_rate
FROM `your_project.workflows`
GROUP BY campaignId
ORDER BY conversion_rate DESC
```
</file>

<file path="implementation_plan.md">
# Plan: Behavioral Influence Engine (V3)

## Goal
Build a programmable motivation engine. Move from "Personalized Notifications" to a robust system that can inject behavioral context into any campaign.

## Core Architecture
**Pipeline**: `Campaign Intent` ‚Üí `User Selection` ‚Üí `Context Resolution` ‚Üí `Rendering` ‚Üí `Delivery`

## Detailed Implementation Steps

### 1. Data Layer: Context Resolution (`functions/src/services/user.ts`)
*   **Rename**: `resolvePersonalizationContext(uid: string)` (was `buildUserContext`)
*   **Robustness**: Ensure stability. Never throw on missing data.
    ```typescript
    return {
      displayName: safeString(user?.displayName, "Friend"),
      timezone: user?.timezone ?? "UTC", // Default to UTC
      // Future: daysSinceLastLog, currentStreak, etc.
    };
    ```

### 2. Logic Layer: Campaign Abstraction (`functions/src/campaigns/types.ts`)
*   **Interface**: Decouple campaign logic from handlers.
    ```typescript
    interface Campaign {
      id: string;
      templateId: string;
      // Returns devices that *should* receive this campaign
      selectEligibleDevices(): Promise<DeviceDocument[]>;
    }
    ```
*   **Implementation**: `DailyNudgeCampaign` implements this interface.

### 3. Infrastructure: Template Registry (`functions/src/config/templates.ts`)
*   **Definition**: Central template config.
    ```typescript
    export const TEMPLATES = {
      WEIGHT_REMINDER_V1: {
        id: "weight_reminder_v1",
        title: "Good morning, {{displayName}}! ‚öñÔ∏è",
        body: "Time to log your weight."
      }
    };
    ```

### 4. Operational Layer: Orchestration & Delivery (`functions/src/handlers/sendDailyNudge.ts`)
*   **Chunking Strategy**:
    *   **Selection**: Fetch all eligible devices.
    *   **Context Batching**: Process 500 UIDs at a time to build context (prevents memory spikes).
    *   **Delivery Batching**: `fcm.sendBatchNotifications` handles its own 500-device limit.
*   **Idempotency**:
    *   **Notification ID**: `${campaignId}_${activeDate}_${uid}`
    *   Example: `weight_reminder_v1_2024-03-20_user123`
    *   Prevents duplicate sends if the job retries.

### 5. Transport Layer: "Dumb" FCM (`functions/src/services/fcm.ts`)
*   **Responsibility**: Pure transport.
*   **Signature**: `sendBatchNotifications(payloads: PreparedNotification[])`

## Verification
1.  **Unit Tests**:
    *   `resolvePersonalizationContext`: Test with null user, empty fields, and valid data.
    *   `renderTemplate`: Test variable replacement.
2.  **Integration**: Run `DailyNudgeCampaign` selection logic to ensure it picks correct devices.
</file>

<file path="README.md">
# Weigh Backend

A minimal Firebase Cloud Functions backend for a mobile weight-tracking app. Built with **TypeScript** and **Node.js 20**.

## Features

- **Device Registration**: Register devices for push notifications using `deviceId` as the identifier
- **Daily Push Notifications**: Scheduled Cloud Function sends weight logging reminders
- **AI Food Analysis**: Analyze food images for nutritional information using GPT-4 Vision

## Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Mobile App    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ           Firebase Cloud Functions        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
                        ‚îÇ  ‚îÇ  register-  ‚îÇ  ‚îÇ   analyze-food-   ‚îÇ  ‚îÇ
                        ‚îÇ  ‚îÇ   device    ‚îÇ  ‚îÇ      image        ‚îÇ  ‚îÇ
                        ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
                        ‚îÇ         ‚îÇ                   ‚îÇ            ‚îÇ
                        ‚îÇ         ‚ñº                   ‚ñº            ‚îÇ
                        ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
                        ‚îÇ  ‚îÇ  Firestore  ‚îÇ     ‚îÇ  OpenAI   ‚îÇ       ‚îÇ
                        ‚îÇ  ‚îÇ  (devices)  ‚îÇ     ‚îÇ  GPT-4V   ‚îÇ       ‚îÇ
                        ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
                        ‚îÇ         ‚ñ≤                                ‚îÇ
                        ‚îÇ         ‚îÇ                                ‚îÇ
                        ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                         ‚îÇ
                        ‚îÇ  ‚îÇ dailyNudge  ‚îÇ‚óÄ‚îÄ‚îÄ Cloud Scheduler      ‚îÇ
                        ‚îÇ  ‚îÇ (scheduled) ‚îÇ    (9:00 AM UTC)        ‚îÇ
                        ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                         ‚îÇ
                        ‚îÇ         ‚îÇ                                ‚îÇ
                        ‚îÇ         ‚ñº                                ‚îÇ
                        ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                         ‚îÇ
                        ‚îÇ  ‚îÇ     FCM     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂ Push Notifications ‚îÇ
                        ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                         ‚îÇ
                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Prerequisites

- [Node.js 20](https://nodejs.org/)
- [Firebase CLI](https://firebase.google.com/docs/cli)
- An existing Firebase project with:
  - Cloud Functions enabled (Blaze plan required)
  - Firestore database created
  - Cloud Messaging (FCM) enabled
- [OpenAI API key](https://platform.openai.com/) with GPT-4 Vision access

## Project Structure

```
Weigh_Backend/
‚îú‚îÄ‚îÄ .github/workflows/
‚îÇ   ‚îî‚îÄ‚îÄ deploy.yml          # GitHub Actions CI/CD
‚îú‚îÄ‚îÄ functions/
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index.ts        # Function exports
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config/         # Configuration constants
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ handlers/       # HTTP and scheduled handlers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/       # Firestore, FCM, Vision services
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ types/          # TypeScript interfaces
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils/          # Validation and error handling
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îî‚îÄ‚îÄ tsconfig.json
‚îú‚îÄ‚îÄ firebase.json           # Firebase configuration
‚îú‚îÄ‚îÄ firestore.rules         # Security rules
‚îî‚îÄ‚îÄ README.md
```

## Setup Instructions

### 1. Clone and Install

```bash
git clone https://github.com/YOUR_USERNAME/Weigh_Backend.git
cd Weigh_Backend
cd functions && npm install
```

### 2. Configure Firebase

Update `.firebaserc` with your Firebase project ID:

```json
{
  "projects": {
    "default": "your-firebase-project-id"
  }
}
```

Login to Firebase CLI:

```bash
firebase login
```

### 3. Set Environment Variables

For local development, set the OpenAI API key:

```bash
firebase functions:secrets:set OPENAI_API_KEY
```

When prompted, enter your OpenAI API key.

### 4. Local Development

Start the Firebase emulators:

```bash
firebase emulators:start --only functions,firestore
```

The emulator will be available at `http://localhost:5001`.

### 5. Deploy to Firebase

Manual deployment:

```bash
firebase deploy --only functions,firestore:rules
```

## GitHub Actions Setup (CI/CD)

### Required Secrets

Add these secrets to your GitHub repository (`Settings > Secrets and variables > Actions`):

| Secret | Description |
|--------|-------------|
| `FIREBASE_PROJECT_ID` | Your Firebase project ID |
| `FIREBASE_SERVICE_ACCOUNT` | Service account JSON key (see below) |

### Generate Service Account Key

1. Go to [Firebase Console](https://console.firebase.google.com/) > Project Settings > Service accounts
2. Click "Generate new private key"
3. Copy the entire JSON content
4. Add it as `FIREBASE_SERVICE_ACCOUNT` secret in GitHub

### Trigger Deployment

Push to `main` branch to trigger automatic deployment, or use "Run workflow" in GitHub Actions.

## API Reference

### POST /register-device

Register or update a device for push notifications.

**Request:**
```json
{
  "deviceId": "unique-device-id",
  "fcmToken": "firebase-cloud-messaging-token",
  "platform": "ios" | "android"
}
```

**Response:**
```json
{
  "success": true,
  "message": "Device registered successfully"
}
```

### POST /analyze-food-image

Analyze a food image and get nutritional estimates.

**Request (JSON):**
```json
{
  "deviceId": "unique-device-id",
  "image": "base64-encoded-image-data"
}
```

**Request (Multipart):**
```
Content-Type: multipart/form-data

deviceId: unique-device-id
image: [file upload]
```

**Response:**
```json
{
  "success": true,
  "nutrition": {
    "foodName": "Grilled Chicken Salad",
    "calories": 350,
    "protein": 35,
    "carbohydrates": 15,
    "fat": 18,
    "fiber": 5,
    "estimatedServingSize": "1 bowl (approximately 300g)"
  }
}
```

**Limits:**
- Max image size: 5MB
- Supported formats: JPEG, PNG, WebP
- Timeout: 60 seconds

## Firestore Schema

### Collection: `devices`

| Field | Type | Description |
|-------|------|-------------|
| `deviceId` | string | Document ID |
| `fcmToken` | string | FCM token |
| `platform` | string | "ios" or "android" |
| `createdAt` | timestamp | First registration |
| `lastSeenAt` | timestamp | Updated on each registration |

### Collection: `nudges`

| Field | Type | Description |
|-------|------|-------------|
| `deviceId` | string | Target device |
| `sentAt` | timestamp | When sent |
| `status` | string | "success" or "failed" |
| `title` | string | Notification title |
| `body` | string | Notification body |
| `error` | string | Error message (if failed) |

## Error Handling

All endpoints return consistent error responses:

```json
{
  "success": false,
  "error": "Error message",
  "code": "ERROR_CODE"
}
```

| HTTP Code | Error Code | Description |
|-----------|------------|-------------|
| 400 | `INVALID_REQUEST` | Missing or invalid input |
| 405 | - | Method not allowed |
| 413 | `IMAGE_TOO_LARGE` | Image exceeds 5MB |
| 415 | `UNSUPPORTED_FORMAT` | Invalid image format |
| 422 | `ANALYSIS_FAILED` | Vision API couldn't analyze |
| 500 | `INTERNAL_ERROR` | Server error |

## Development

### Build

```bash
cd functions
npm run build
```

### Lint

```bash
cd functions
npm run lint
```

### Watch Mode

```bash
cd functions
npm run build:watch
```

## Security Notes

- No Firebase Auth is used; `deviceId` is the only identifier
- All Firestore access is denied to clients (backend-only)
- OpenAI API key is stored as a Firebase secret
- Images are not stored server-side

## License

MIT
</file>

<file path="storage.rules">
rules_version = '2';
service firebase.storage {
  match /b/{bucket}/o {
    // User-specific backup files
    match /users/{uid}/backups/{file} {
      allow read, write: if request.auth != null && request.auth.uid == uid;
    }
    
    // Deny all other access by default
    match /{allPaths=**} {
      allow read, write: if false;
    }
  }
}
</file>

<file path="functions/src/handlers/quickScan.ts">
import { Request, Response } from "express";
import { logger } from "firebase-functions/v2";
import Busboy from "busboy";
import { quickAnalyzeFood } from "../services/vision";
import { deductCredit } from "../services/user";
import { foodAnalysisSchema, validateInput } from "../utils/validation";
import { handleError, errors } from "../utils/errors";
import { LIMITS, VISION_CONFIG } from "../config/constants";
import { AuthenticatedRequest, verifyAuth } from "../middleware/auth";

// Extend Express Request to include rawBody (added by Firebase Functions)
interface FirebaseRequest extends Request {
    rawBody?: Buffer;
}

interface ParsedRequest {
    imageBase64: string;
    mimeType: string;
}

function parseMultipartRequest(req: FirebaseRequest): Promise<ParsedRequest> {
  return new Promise((resolve, reject) => {
    // eslint-disable-next-line new-cap
    const bb = Busboy({
      headers: req.headers,
      limits: {
        fileSize: LIMITS.MAX_IMAGE_SIZE_BYTES,
        files: 1,
      },
    });

    let imageBuffer: Buffer | null = null;
    let mimeType = "";
    let fileLimitExceeded = false;

    bb.on("file", (
      _fieldname: string,
      file: NodeJS.ReadableStream,
      info: { filename: string; encoding: string; mimeType: string },
    ) => {
      mimeType = info.mimeType;
      const chunks: Buffer[] = [];

      file.on("data", (chunk: Buffer) => {
        chunks.push(chunk);
      });

      file.on("limit", () => {
        fileLimitExceeded = true;
      });

      file.on("end", () => {
        imageBuffer = Buffer.concat(chunks);
      });
    });

    bb.on("finish", () => {
      if (fileLimitExceeded) {
        reject(errors.imageTooLarge(LIMITS.MAX_IMAGE_SIZE_BYTES));
        return;
      }

      if (!imageBuffer) {
        reject(errors.invalidRequest("No image provided"));
        return;
      }

      resolve({
        imageBase64: imageBuffer.toString("base64"),
        mimeType,
      });
    });

    bb.on("error", (error: Error) => {
      reject(error);
    });

    // Handle the case where body is already parsed (e.g., by Firebase Functions)
    if (req.rawBody) {
      bb.end(req.rawBody);
    } else {
      req.pipe(bb);
    }
  });
}

function parseJsonRequest(req: Request): ParsedRequest {
  const validation = validateInput(foodAnalysisSchema, req.body);
  if (!validation.success) {
    throw errors.invalidRequest(validation.error);
  }

  const { image } = validation.data;

  if (!image) {
    throw errors.invalidRequest("image is required");
  }

  return {
    imageBase64: image,
    mimeType: "image/jpeg", // Assume JPEG for base64
  };
}

// Create a mutable copy of supported formats for includes check
const supportedFormats: string[] = [...VISION_CONFIG.SUPPORTED_FORMATS];

/**
 * Quick Scan Handler
 * Lightweight food identification - returns food name, confidence, calories, one-liner
 * Requires authentication and deducts 1 credit per scan
 */
export async function quickScan(
  req: FirebaseRequest & AuthenticatedRequest,
  res: Response,
): Promise<void> {
  try {
    // Only allow POST
    if (req.method !== "POST") {
      res.status(405).json({
        success: false,
        error: "Method not allowed",
      });
      return;
    }

    // Verify authentication
    await new Promise<void>((resolve, reject) => {
      verifyAuth(req, res, (err?: unknown) => {
        if (err) reject(err);
        else resolve();
      });
    });

    // If verifyAuth responded with error, stop here
    if (res.headersSent) return;

    const uid = req.uid!; // Safe: verifyAuth ensures uid exists
    logger.info(`Quick scan for user: ${uid}`);

    // Deduct credit before analysis (throws if insufficient)
    const remainingCredits = await deductCredit(uid);
    logger.info(`Credit deducted, remaining: ${remainingCredits}`);

    let parsed: ParsedRequest;

    // Parse based on content type
    const contentType = req.headers["content-type"] || "";
    if (contentType.includes("multipart/form-data")) {
      parsed = await parseMultipartRequest(req);
    } else if (contentType.includes("application/json")) {
      parsed = parseJsonRequest(req);
    } else {
      throw errors.invalidRequest(
        "Content-Type must be multipart/form-data or application/json",
      );
    }

    // Validate image format
    if (!supportedFormats.includes(parsed.mimeType)) {
      throw errors.unsupportedFormat([...VISION_CONFIG.SUPPORTED_FORMATS]);
    }

    // Quick analyze the food image
    const result = await quickAnalyzeFood(parsed.imageBase64);

    res.status(200).json({
      success: true,
      ...result,
      creditsRemaining: remainingCredits,
    });
  } catch (error) {
    handleError(error, res);
  }
}
</file>

<file path="functions/src/services/firestore.ts">
import * as admin from "firebase-admin";
import { logger } from "firebase-functions/v2";
import { COLLECTIONS, LIMITS } from "../config/constants";
import { DeviceDocument, NudgeDocument } from "../types";

// Initialize Firebase Admin if not already initialized
if (!admin.apps.length) {
  admin.initializeApp();
}

const db = admin.firestore();

// Device operations
export async function upsertDevice(
  uid: string,
  deviceId: string,
  fcmToken: string,
  platform: "ios" | "android",
): Promise<void> {
  const deviceRef = db.collection(COLLECTIONS.DEVICES).doc(deviceId);
  const now = admin.firestore.Timestamp.now();

  const deviceDoc = await deviceRef.get();

  if (deviceDoc.exists) {
    // Update existing device
    // We update the UID to ensure the device is 'claimed' by the current logged-in user
    await deviceRef.update({
      uid,
      fcmToken,
      platform,
      lastSeenAt: now,
    });
    logger.info(`Updated device: ${deviceId} for user: ${uid}`);
  } else {
    // Create new device
    const newDevice: DeviceDocument = {
      deviceId,
      uid,
      fcmToken,
      platform,
      createdAt: now,
      lastSeenAt: now,
    };
    await deviceRef.set(newDevice);
    logger.info(`Registered new device: ${deviceId} for user: ${uid}`);
  }
}

export async function getActiveDevices(): Promise<DeviceDocument[]> {
  const cutoffDate = new Date();
  cutoffDate.setDate(cutoffDate.getDate() - LIMITS.DEVICE_ACTIVE_DAYS);
  const cutoffTimestamp = admin.firestore.Timestamp.fromDate(cutoffDate);

  const snapshot = await db
    .collection(COLLECTIONS.DEVICES)
    .where("lastSeenAt", ">=", cutoffTimestamp)
    .get();

  return snapshot.docs.map((doc) => doc.data() as DeviceDocument);
}

// Nudge operations
export async function logNudge(nudge: Omit<NudgeDocument, "sentAt">): Promise<void> {
  const nudgeData: NudgeDocument = {
    ...nudge,
    sentAt: admin.firestore.Timestamp.now(),
  };

  await db.collection(COLLECTIONS.NUDGES).add(nudgeData);
  logger.info(`Logged nudge for device: ${nudge.deviceId}`, {
    status: nudge.status,
  });
}

export { db, admin };
</file>

<file path="functions/src/services/user.ts">
import { getFirestore, FieldValue, Timestamp } from "firebase-admin/firestore";
import { logger } from "firebase-functions/v2";
import { errors } from "../utils/errors";

const db = getFirestore();

// Default free credits for new users
const DEFAULT_FREE_CREDITS = 20;

/**
 * Safe string extraction with fallback.
 * Never throws, always returns a string.
 */
function safeString(value: unknown, fallback: string): string {
  if (typeof value === "string" && value.trim().length > 0) {
    return value.trim();
  }
  return fallback;
}

/**
 * Derives time of day from timezone.
 * Returns "morning", "afternoon", or "evening" based on local hour.
 */
function getTimeOfDay(timezone: string): "morning" | "afternoon" | "evening" {
  try {
    const now = new Date();
    const formatter = new Intl.DateTimeFormat("en-US", {
      timeZone: timezone,
      hour: "numeric",
      hour12: false,
    });
    const hour = parseInt(formatter.format(now), 10);

    if (hour >= 5 && hour < 12) return "morning";
    if (hour >= 12 && hour < 17) return "afternoon";
    return "evening";
  } catch {
    // Invalid timezone, default to morning
    return "morning";
  }
}

/**
 * Personalization context for notification rendering.
 * Designed for Tier 1 variables now, extensible for Tier 2 (streaks, etc).
 */
export interface PersonalizationContext {
  displayName: string;
  timezone: string;
  timeOfDay: "morning" | "afternoon" | "evening";
  // Tier 2 (future): daysSinceLastLog, currentStreak, goalType
}

/**
 * User document structure
 */
export interface UserDocument {
  aiCredits: number;
  totalGranted: number;
  totalUsed: number;
  displayName?: string;
  timezone?: string;
  createdAt: Timestamp;
  lastActiveAt: Timestamp;
  updatedAt?: Timestamp;
}

/**
 * Initialize a new user with free credits
 * Called on first authentication
 */
export async function initializeUser(uid: string): Promise<UserDocument> {
  const userRef = db.collection("users").doc(uid);

  const existingUser = await userRef.get();
  if (existingUser.exists) {
    logger.info(`User ${uid} already exists, returning existing data`);
    return existingUser.data() as UserDocument;
  }

  const now = Timestamp.now();
  const userData: UserDocument = {
    aiCredits: DEFAULT_FREE_CREDITS,
    totalGranted: DEFAULT_FREE_CREDITS,
    totalUsed: 0,
    createdAt: now,
    lastActiveAt: now,
  };

  await userRef.set(userData);
  logger.info(`Initialized new user ${uid} with ${DEFAULT_FREE_CREDITS} credits`);

  return userData;
}

/**
 * Get or create user data
 */
export async function getOrCreateUser(uid: string): Promise<UserDocument> {
  const userRef = db.collection("users").doc(uid);
  const userDoc = await userRef.get();

  if (!userDoc.exists) {
    return initializeUser(uid);
  }

  // Update last active timestamp
  await userRef.update({ lastActiveAt: FieldValue.serverTimestamp() });

  return userDoc.data() as UserDocument;
}

/**
 * Get current credit balance
 */
export async function getCredits(uid: string): Promise<number> {
  const user = await getOrCreateUser(uid);
  return user.aiCredits;
}

/**
 * Deduct one credit from user balance
 * Uses transaction to prevent race conditions
 * Throws INSUFFICIENT_CREDITS if balance is 0
 */
export async function deductCredit(uid: string): Promise<number> {
  const userRef = db.collection("users").doc(uid);

  const newBalance = await db.runTransaction(async (transaction) => {
    const userDoc = await transaction.get(userRef);

    if (!userDoc.exists) {
      // Initialize user first
      const now = Timestamp.now();
      const userData: UserDocument = {
        aiCredits: DEFAULT_FREE_CREDITS,
        totalGranted: DEFAULT_FREE_CREDITS,
        totalUsed: 0,
        createdAt: now,
        lastActiveAt: now,
      };
      transaction.set(userRef, userData);
      // Deduct one credit
      transaction.update(userRef, {
        aiCredits: DEFAULT_FREE_CREDITS - 1,
        totalUsed: 1,
        lastActiveAt: FieldValue.serverTimestamp(),
      });
      return DEFAULT_FREE_CREDITS - 1;
    }

    const userData = userDoc.data() as UserDocument;

    if (userData.aiCredits <= 0) {
      throw errors.insufficientCredits();
    }

    const newCredits = userData.aiCredits - 1;
    transaction.update(userRef, {
      aiCredits: newCredits,
      totalUsed: FieldValue.increment(1),
      lastActiveAt: FieldValue.serverTimestamp(),
    });

    return newCredits;
  });

  logger.info(`Deducted credit for user ${uid}, remaining: ${newBalance}`);
  return newBalance;
}

/**
 * Add credits to user balance (for future admin/payment use)
 */
export async function addCredits(uid: string, amount: number): Promise<number> {
  const userRef = db.collection("users").doc(uid);

  await userRef.update({
    aiCredits: FieldValue.increment(amount),
    totalGranted: FieldValue.increment(amount),
    lastActiveAt: FieldValue.serverTimestamp(),
  });

  const updated = await userRef.get();
  const credits = (updated.data() as UserDocument).aiCredits;

  logger.info(`Added ${amount} credits to user ${uid}, new balance: ${credits}`);
  return credits;
}

// ============================================================================
// PERSONALIZATION FUNCTIONS
// ============================================================================

/**
 * Upsert user profile fields (displayName, timezone).
 * Only updates fields that are provided (undefined fields are ignored).
 * Never throws - profile is not critical to registration.
 */
export async function upsertUserProfile(
  uid: string,
  data: { displayName?: string; timezone?: string },
): Promise<void> {
  const userRef = db.collection("users").doc(uid);
  const now = Timestamp.now();

  const updateData: Record<string, unknown> = {
    updatedAt: now,
    lastActiveAt: now,
  };

  if (data.displayName !== undefined) {
    updateData.displayName = data.displayName;
  }
  if (data.timezone !== undefined) {
    updateData.timezone = data.timezone;
  }

  try {
    const doc = await userRef.get();
    if (doc.exists) {
      await userRef.update(updateData);
      logger.info(`Updated user profile: ${uid}`);
    } else {
      // Create new profile with defaults + credits
      const newProfile: UserDocument = {
        aiCredits: DEFAULT_FREE_CREDITS,
        totalGranted: DEFAULT_FREE_CREDITS,
        totalUsed: 0,
        displayName: safeString(data.displayName, ""),
        timezone: safeString(data.timezone, "UTC"),
        createdAt: now,
        lastActiveAt: now,
        updatedAt: now,
      };
      await userRef.set(newProfile);
      logger.info(`Created user profile: ${uid} with ${DEFAULT_FREE_CREDITS} credits`);
    }
  } catch (error) {
    logger.error(`Failed to upsert user profile: ${uid}`, { error });
    // Don't throw - user profile is not critical to registration
  }
}

/**
 * Resolves personalization context for a single user.
 * NEVER throws - always returns a valid context with safe defaults.
 */
export async function resolvePersonalizationContext(
  uid: string,
): Promise<PersonalizationContext> {
  try {
    const doc = await db.collection("users").doc(uid).get();
    const data = doc.data() as UserDocument | undefined;

    const displayName = safeString(data?.displayName, "Friend");
    const timezone = safeString(data?.timezone, "UTC");

    return {
      displayName,
      timezone,
      timeOfDay: getTimeOfDay(timezone),
    };
  } catch (error) {
    logger.warn(`Failed to resolve context for ${uid}, using defaults`, { error });
    return {
      displayName: "Friend",
      timezone: "UTC",
      timeOfDay: "morning",
    };
  }
}

/**
 * Batch resolve personalization context for multiple users.
 * Efficient for processing large numbers of users (uses Firestore getAll).
 *
 * @param uids Array of user IDs to resolve
 * @returns Map of uid -> PersonalizationContext
 */
export async function resolveContextBatch(
  uids: string[],
): Promise<Map<string, PersonalizationContext>> {
  const contextMap = new Map<string, PersonalizationContext>();

  if (uids.length === 0) {
    return contextMap;
  }

  try {
    // Get document references for all UIDs
    const refs = uids.map((uid) => db.collection("users").doc(uid));
    const snapshots = await db.getAll(...refs);

    for (let i = 0; i < uids.length; i++) {
      const uid = uids[i];
      const snapshot = snapshots[i];
      const data = snapshot.exists ? (snapshot.data() as UserDocument) : undefined;

      const displayName = safeString(data?.displayName, "Friend");
      const timezone = safeString(data?.timezone, "UTC");

      contextMap.set(uid, {
        displayName,
        timezone,
        timeOfDay: getTimeOfDay(timezone),
      });
    }
  } catch (error) {
    logger.warn("Failed to batch resolve contexts, using defaults", { error });
    // Return defaults for all uids
    for (const uid of uids) {
      contextMap.set(uid, {
        displayName: "Friend",
        timezone: "UTC",
        timeOfDay: "morning",
      });
    }
  }

  return contextMap;
}
</file>

<file path="functions/src/types/visionSchemas.ts">
import { z } from "zod";

// =============================================================================
// Error Types
// =============================================================================

export const VisionErrorTypeSchema = z.enum([
  "NOT_FOOD",
  "BLURRY",
  "LOW_CONFIDENCE",
  "MULTIPLE_ITEMS",
]);
export type VisionErrorType = z.infer<typeof VisionErrorTypeSchema>;

export const VisionErrorSchema = z.object({
  error: z.string(),
  errorType: VisionErrorTypeSchema,
});
export type VisionError = z.infer<typeof VisionErrorSchema>;

// =============================================================================
// Debug / Confidence
// =============================================================================

export const ItemDebugSchema = z.object({
  confidence: z.number().min(0).max(1),
  visualCues: z.array(z.string()),
});
export type ItemDebug = z.infer<typeof ItemDebugSchema>;

// =============================================================================
// 2-Stage Architecture: Perception (Stage 1)
// =============================================================================

export const PerceptionItemSchema = z.object({
  foodName: z.string(),
  estimatedWeight_g: z.number().positive(),
  confidence: z.number().min(0).max(1),
});
export type PerceptionItem = z.infer<typeof PerceptionItemSchema>;

export const PerceptionResultSchema = z.object({
  items: z.array(PerceptionItemSchema).min(1).max(5),
});
export type PerceptionResult = z.infer<typeof PerceptionResultSchema>;

// =============================================================================
// 2-Stage Architecture: Nutrition (Stage 2)
// =============================================================================

export const NutritionItemSchema = z.object({
  foodName: z.string(),
  calories: z.number().nonnegative(),
  protein: z.number().nonnegative(),
  carbohydrates: z.number().nonnegative(),
  fat: z.number().nonnegative(),
  fiber: z.number().nonnegative(),
});
export type NutritionItem = z.infer<typeof NutritionItemSchema>;

export const NutritionResultSchema = z.object({
  items: z.array(NutritionItemSchema).min(1).max(5),
});
export type NutritionResult = z.infer<typeof NutritionResultSchema>;

// =============================================================================
// Food Item (per-item nutrition)
// =============================================================================

export const FoodItemSchema = z.object({
  foodName: z.string(),
  estimatedWeight_g: z.number().positive(),
  calories: z.number().nonnegative(),
  protein: z.number().nonnegative(),
  carbohydrates: z.number().nonnegative(),
  fat: z.number().nonnegative(),
  fiber: z.number().nonnegative(),
  // Latent canonical attributes (not exposed in reasoning)
  _canonical: z.object({
    cuisine: z.string(),
    baseIngredients: z.array(z.string()),
    cookingMethod: z.string(),
    density: z.enum(["low", "medium", "high"]),
    moisture: z.enum(["dry", "moist", "wet"]),
    processingLevel: z.enum(["raw", "minimal", "processed", "ultra-processed"]),
  }),
  _debug: ItemDebugSchema,
});
export type FoodItem = z.infer<typeof FoodItemSchema>;

// =============================================================================
// Vision Pass Result (multi-item response)
// =============================================================================

export const VisionPassResultSchema = z.object({
  items: z.array(FoodItemSchema).min(1).max(5),
  totalWeight_g: z.number().positive(),
  totalCalories: z.number().nonnegative(),
});
export type VisionPassResult = z.infer<typeof VisionPassResultSchema>;

// =============================================================================
// Combined Response (success or error)
// =============================================================================

export const VisionResponseSchema = z.union([
  VisionPassResultSchema,
  VisionErrorSchema,
]);
export type VisionResponse = z.infer<typeof VisionResponseSchema>;

// =============================================================================
// Persistence: Analysis Record (Firestore)
// =============================================================================

export const AnalysisStatusSchema = z.enum([
  "SINGLE_PASS",
  "TWO_STAGE",
  "TWO_PASS_AGREED",
  "TWO_PASS_DIVERGED",
]);
export type AnalysisStatus = z.infer<typeof AnalysisStatusSchema>;

export const DivergenceReasonSchema = z.enum([
  "CALORIES",
  "WEIGHT",
  "ITEM_MISMATCH",
]).optional();
export type DivergenceReason = z.infer<typeof DivergenceReasonSchema>;

export const FoodAnalysisRecordSchema = z.object({
  // Identity
  imageHash: z.string(),
  imageByteLength: z.number(), // Salt for hash collision safety

  // Model metadata
  model: z.string(),
  promptVersion: z.string(),

  // 2-Stage Architecture: Perception (Stage 1)
  perceptionRawText: z.string().optional(),
  perceptionParsed: PerceptionResultSchema.optional(),
  perceptionDurationMs: z.number().optional(),

  // 2-Stage Architecture: Nutrition (Stage 2)
  nutritionRawText: z.string().optional(),
  nutritionParsed: NutritionResultSchema.optional(),
  nutritionDurationMs: z.number().optional(),

  // Legacy: Pass 1 (single pass mode)
  pass1RawText: z.string().optional(),
  pass1Parsed: VisionPassResultSchema.optional(),

  // Legacy: Pass 2 (optional - only if triggered)
  pass2RawText: z.string().optional(),
  pass2Parsed: VisionPassResultSchema.optional(),

  // Final result
  status: AnalysisStatusSchema,
  divergenceReason: DivergenceReasonSchema,
  finalResult: VisionPassResultSchema,

  // Timestamps
  createdAt: z.date(),
  durationMs: z.number(),
});
export type FoodAnalysisRecord = z.infer<typeof FoodAnalysisRecordSchema>;

// =============================================================================
// Helper: Check if response is an error
// =============================================================================

export function isVisionError(
  response: VisionResponse,
): response is VisionError {
  return "error" in response && "errorType" in response;
}
</file>

<file path=".gitignore">
# Dependencies
node_modules/
functions/node_modules/
functions/lib/

# Firebase
.firebase/
firebase-debug.log
firestore-debug.log
ui-debug.log
pubsub-debug.log

# Environment
.env
.env.local
.env.*.local
*.env
.env.*

# IDE
.idea/
.vscode/
*.swp
*.swo
*~

# OS
.DS_Store
Thumbs.db

# Logs
logs/
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# Build artifacts
dist/
build/
*.tsbuildinfo

# Test coverage
coverage/

# Misc
*.bak
*.tmp
</file>

<file path="firebase.json">
{
    "functions": {
        "source": "functions",
        "runtime": "nodejs20",
        "predeploy": [
            "npm --prefix \"$RESOURCE_DIR\" run lint",
            "npm --prefix \"$RESOURCE_DIR\" run build"
        ]
    },
    "firestore": {
        "rules": "firestore.rules",
        "indexes": "firestore.indexes.json"
    },
    "storage": {
        "rules": "storage.rules"
    }
}
</file>

<file path="firestore.rules">
rules_version = '2';
service cloud.firestore {
  match /databases/{database}/documents {
    // All Firestore access is through Cloud Functions only
    // No direct client access allowed
    
    // Devices collection - backend only
    match /devices/{deviceId} {
      allow read, write: if false;
    }
    
    // Nudges collection - backend only
    match /nudges/{nudgeId} {
      allow read, write: if false;
    }
    
    // Workflows collection - backend only (deferred deep linking)
    match /workflows/{workflowId} {
      allow read, write: if false;
    }
    
    // Deny all other access
    match /{document=**} {
      allow read, write: if false;
    }
  }
}
</file>

<file path="specs.md">
### 2. The Missing Link: Connecting Auth to Push Notifications

Currently, your `register-device` endpoint is **public** and **unaware** of the user. We need to lock the `deviceId` to the `uid`.

Here is the plan to unify them:

1.  **Secure the Endpoint:** Make `/register-device` require a Firebase Token.
2.  **Store the Link:** Save the `uid` inside the `devices` collection.

#### Step 1: Update `functions/src/services/firestore.ts`

We need to update the `upsertDevice` function to accept and store the `uid`.

```typescript
// functions/src/services/firestore.ts

import * as admin from "firebase-admin";
import { logger } from "firebase-functions/v2";
import { COLLECTIONS, LIMITS } from "../config/constants";
import { DeviceDocument, NudgeDocument } from "../types";

// ... existing init code ...

const db = admin.firestore();

// Update interface (Optional: add to types/index.ts as well)
export interface DeviceDocument {
  deviceId: string;
  uid: string; // <--- NEW FIELD
  fcmToken: string;
  platform: "ios" | "android";
  createdAt: FirebaseFirestore.Timestamp;
  lastSeenAt: FirebaseFirestore.Timestamp;
}

// Updated upsert function
export async function upsertDevice(
  uid: string, // <--- NEW PARAM
  deviceId: string,
  fcmToken: string,
  platform: "ios" | "android",
): Promise<void> {
  const deviceRef = db.collection(COLLECTIONS.DEVICES).doc(deviceId);
  const now = admin.firestore.Timestamp.now();

  const deviceDoc = await deviceRef.get();

  if (deviceDoc.exists) {
    // Update existing device
    // We update the UID to ensure the device is 'claimed' by the current logged-in user
    await deviceRef.update({
      uid, 
      fcmToken,
      platform,
      lastSeenAt: now,
    });
    logger.info(`Updated device: ${deviceId} for user: ${uid}`);
  } else {
    // Create new device
    const newDevice: DeviceDocument = {
      deviceId,
      uid,
      fcmToken,
      platform,
      createdAt: now,
      lastSeenAt: now,
    };
    await deviceRef.set(newDevice);
    logger.info(`Registered new device: ${deviceId} for user: ${uid}`);
  }
}

// ... rest of the file ...
```

#### Step 2: Update `functions/src/handlers/registerDevice.ts`

Now we secure the handler so it extracts the `uid` from the token.

```typescript
// functions/src/handlers/registerDevice.ts

import { Request, Response } from "express";
import { logger } from "firebase-functions/v2";
import { upsertDevice } from "../services/firestore";
import { trackEventAsync } from "../services/events";
import { deviceRegistrationSchema, validateInput } from "../utils/validation";
import { handleError, errors } from "../utils/errors";
import { EventName } from "../types/behavioral";
import { AuthenticatedRequest, verifyAuth } from "../middleware/auth"; // Import Auth

export async function registerDevice(
  req: Request & AuthenticatedRequest, // Add AuthenticatedRequest type
  res: Response
): Promise<void> {
  try {
    if (req.method !== "POST") {
      res.status(405).json({ success: false, error: "Method not allowed" });
      return;
    }

    // 1. VERIFY AUTH
    // This connects the request to the Firebase User (Anonymous or Gmail)
    await new Promise<void>((resolve, reject) => {
      verifyAuth(req, res, (err?: unknown) => {
        if (err) reject(err);
        else resolve();
      });
    });
    if (res.headersSent) return;

    const uid = req.uid!; // Securely obtained from token

    // 2. Validate input
    const validation = validateInput(deviceRegistrationSchema, req.body);
    if (!validation.success) {
      throw errors.invalidRequest(validation.error);
    }

    const { deviceId, fcmToken, platform, timezone } = validation.data;

    logger.info(`Registering device: ${deviceId} to User: ${uid}`);

    // 3. Upsert with UID
    await upsertDevice(uid, deviceId, fcmToken, platform);

    // 4. Track Event (Now properly attributed to the UID)
    if (timezone) {
      trackEventAsync({
        eventName: EventName.DEVICE_REGISTERED,
        userId: uid, // Use actual UID now, not deviceId
        timestamp: new Date().toISOString(),
        timezone,
        platform,
        metadata: {
          timezone,
          platform,
          deviceId // Keep deviceId in metadata for reference
        },
      }).catch((err) => {
        logger.warn("Failed to track device registration event", { error: err });
      });
    }

    res.status(200).json({
      success: true,
      message: "Device registered successfully",
    });
  } catch (error) {
    handleError(error, res);
  }
}
```

### 3. How the User Journey flows now

1.  **App Launch (Fresh Install):**
    *   Client SDK: `auth().signInAnonymously()` -> Returns `User A`.
    *   Client: Calls `POST /register-device` with Token A.
    *   **Backend:** Locks Device ID `D1` to User `A`.

2.  **Daily Nudge:**
    *   Scheduler runs. It grabs `D1` from the database.
    *   Sends Push Notification.
    *   It works because the device token is fresh.

3.  **User Links Gmail (Optional):**
    *   Client SDK: `user.linkWithCredential(googleCred)`.
    *   User is still `User A`, but now has an email attached.
    *   Client: Calls `POST /register-device` again (on next launch or immediately).
    *   **Backend:** Updates `D1` -> `User A`. (No change in ID, just refreshed token).

4.  **Reinstall (Android - The Danger Zone):**
    *   User deletes app. `User A` is wiped from phone.
    *   User reinstalls. `auth().signInAnonymously()` -> Returns **`User B`** (New ID).
    *   Client: Calls `POST /register-device`.
    *   **Backend:** Updates `D1` -> **`User B`**.
    *   *Result:* The device is now owned by the new empty account. The old history is "orphaned" in `User A`.
    *   *Recovery:* User clicks "Sign in with Google". Client SDK detects `User A` exists. Logs in as `User A`.
    *   Client: Calls `POST /register-device`.
    *   **Backend:** Updates `D1` -> **`User A`**. History restored.
</file>

<file path="functions/src/handlers/analyzeFoodImage.ts">
import { Request, Response } from "express";
import { logger } from "firebase-functions/v2";
import Busboy from "busboy";
import { analyzeFood } from "../services/vision";
import { deductCredit } from "../services/user";
import { trackEventAsync } from "../services/events";
import { EventName } from "../types/behavioral";
import { foodAnalysisSchema, validateInput } from "../utils/validation";
import { handleError, errors } from "../utils/errors";
import { LIMITS, VISION_CONFIG } from "../config/constants";
import { AuthenticatedRequest, verifyAuth } from "../middleware/auth";

// Extend Express Request to include rawBody (added by Firebase Functions)
interface FirebaseRequest extends Request {
  rawBody?: Buffer;
}

interface ParsedRequest {
  imageBase64: string;
  mimeType: string;
}

function parseMultipartRequest(req: FirebaseRequest): Promise<ParsedRequest> {
  return new Promise((resolve, reject) => {
    // eslint-disable-next-line new-cap
    const bb = Busboy({
      headers: req.headers,
      limits: {
        fileSize: LIMITS.MAX_IMAGE_SIZE_BYTES,
        files: 1,
      },
    });

    let imageBuffer: Buffer | null = null;
    let mimeType = "";
    let fileLimitExceeded = false;

    bb.on("file", (
      _fieldname: string,
      file: NodeJS.ReadableStream,
      info: { filename: string; encoding: string; mimeType: string },
    ) => {
      mimeType = info.mimeType;
      const chunks: Buffer[] = [];

      file.on("data", (chunk: Buffer) => {
        chunks.push(chunk);
      });

      file.on("limit", () => {
        fileLimitExceeded = true;
      });

      file.on("end", () => {
        imageBuffer = Buffer.concat(chunks);
      });
    });

    bb.on("finish", () => {
      if (fileLimitExceeded) {
        reject(errors.imageTooLarge(LIMITS.MAX_IMAGE_SIZE_BYTES));
        return;
      }

      if (!imageBuffer) {
        reject(errors.invalidRequest("No image provided"));
        return;
      }

      resolve({
        imageBase64: imageBuffer.toString("base64"),
        mimeType,
      });
    });

    bb.on("error", (error: Error) => {
      reject(error);
    });

    // Handle the case where body is already parsed (e.g., by Firebase Functions)
    if (req.rawBody) {
      bb.end(req.rawBody);
    } else {
      req.pipe(bb);
    }
  });
}

function parseJsonRequest(req: Request): ParsedRequest {
  const validation = validateInput(foodAnalysisSchema, req.body);
  if (!validation.success) {
    throw errors.invalidRequest(validation.error);
  }

  const { image } = validation.data;

  if (!image) {
    throw errors.invalidRequest("image is required");
  }

  return {
    imageBase64: image,
    mimeType: "image/jpeg", // Assume JPEG for base64
  };
}

// Create a mutable copy of supported formats for includes check
const supportedFormats: string[] = [...VISION_CONFIG.SUPPORTED_FORMATS];

/**
 * Food Image Analysis Handler
 * Requires authentication and deducts 1 credit per analysis
 */
export async function analyzeFoodImage(
  req: FirebaseRequest & AuthenticatedRequest,
  res: Response,
): Promise<void> {
  try {
    // Only allow POST
    if (req.method !== "POST") {
      res.status(405).json({
        success: false,
        error: "Method not allowed",
      });
      return;
    }

    // Verify authentication
    await new Promise<void>((resolve, reject) => {
      verifyAuth(req, res, (err?: unknown) => {
        if (err) reject(err);
        else resolve();
      });
    });

    // If verifyAuth responded with error, stop here
    if (res.headersSent) return;

    const uid = req.uid!; // Safe: verifyAuth ensures uid exists
    logger.info(`Analyzing food image for user: ${uid}`);

    // Deduct credit before analysis (throws if insufficient)
    const remainingCredits = await deductCredit(uid);
    logger.info(`Credit deducted, remaining: ${remainingCredits}`);

    let parsed: ParsedRequest;

    // Parse based on content type
    const contentType = req.headers["content-type"] || "";
    if (contentType.includes("multipart/form-data")) {
      parsed = await parseMultipartRequest(req);
    } else if (contentType.includes("application/json")) {
      parsed = parseJsonRequest(req);
    } else {
      throw errors.invalidRequest(
        "Content-Type must be multipart/form-data or application/json",
      );
    }

    // Validate image format
    if (!supportedFormats.includes(parsed.mimeType)) {
      throw errors.unsupportedFormat([...VISION_CONFIG.SUPPORTED_FORMATS]);
    }

    // Analyze the food image
    const analysisStart = Date.now();
    const nutrition = await analyzeFood(parsed.imageBase64);
    const latencyMs = Date.now() - analysisStart;

    // Track FOOD_ANALYZED event (fire-and-forget)
    trackEventAsync({
      eventName: EventName.FOOD_ANALYZED,
      userId: uid,
      timestamp: new Date().toISOString(),
      timezone: "UTC", // Server doesn't know user timezone here
      platform: "ios", // Default, client should send this
      metadata: {
        success: true,
        food_detected: true,
        credits_remaining: remainingCredits,
        latency_ms: latencyMs,
      },
    }).catch((err) => {
      logger.warn("Failed to track food analysis event", { error: err });
    });

    res.status(200).json({
      success: true,
      nutrition,
      creditsRemaining: remainingCredits,
    });
  } catch (error) {
    handleError(error, res);
  }
}
</file>

<file path="functions/src/services/backup.ts">
import { getFirestore, Timestamp } from "firebase-admin/firestore";
import { getStorage } from "firebase-admin/storage";
import { logger } from "firebase-functions/v2";
import * as zlib from "zlib";
import { promisify } from "util";
import { errors } from "../utils/errors";
import { BACKUP_CONFIG } from "../config/constants";
import type { BackupPayload } from "../types";

const db = getFirestore();
const gzip = promisify(zlib.gzip);
const gunzip = promisify(zlib.gunzip);

// Increment only if backup format changes
const BACKUP_VERSION = 1;

/**
 * Firestore backup metadata (NO payload here)
 */
export interface BackupDocument {
  version: number;
  storagePath: string;
  sizeBytes: number;
  updatedAt: Timestamp;
}

/**
 * Resolve Cloud Storage bucket explicitly
 */
function getBucket() {
  const bucketName = BACKUP_CONFIG.STORAGE_BUCKET;
  if (!bucketName) {
    throw new Error("STORAGE_BUCKET environment variable is not set");
  }
  return getStorage().bucket(bucketName);
}

/**
 * Storage path for the current backup
 * Overwrites on each backup
 */
function getStoragePath(uid: string): string {
  return `${BACKUP_CONFIG.STORAGE_PATH_PREFIX}/${uid}/backups/${BACKUP_CONFIG.BACKUP_FILENAME}`;
}

/**
 * Save backup for a user
 * 1) Compress JSON
 * 2) Upload to Cloud Storage
 * 3) Store metadata in Firestore
 */
export async function saveBackup(
  uid: string,
  payload: BackupPayload,
): Promise<void> {
  const json = JSON.stringify(payload);
  const compressed = await gzip(Buffer.from(json, "utf-8"));

  const storagePath = getStoragePath(uid);
  const bucket = getBucket();
  const file = bucket.file(storagePath);

  // Upload blob FIRST (atomicity guarantee)
  // NOTE: Do NOT set contentEncoding: "gzip" - this causes Cloud Storage to auto-decompress on download
  await file.save(compressed, {
    contentType: "application/gzip",
  });

  logger.info("Backup uploaded to Cloud Storage", {
    uid,
    storagePath,
    sizeBytes: compressed.length,
  });

  // Write Firestore metadata ONLY
  const backupRef = db
    .collection("users")
    .doc(uid)
    .collection("backup")
    .doc("current");

  await backupRef.set({
    version: BACKUP_VERSION,
    storagePath,
    sizeBytes: compressed.length,
    updatedAt: Timestamp.now(),
  });

  logger.info("Backup metadata written", { uid });
}

/**
 * Load backup for a user
 * Reads metadata ‚Üí downloads blob ‚Üí decompresses
 */
export async function loadBackup(uid: string): Promise<BackupPayload> {
  const backupRef = db
    .collection("users")
    .doc(uid)
    .collection("backup")
    .doc("current");

  const snap = await backupRef.get();
  if (!snap.exists) {
    throw errors.backupNotFound();
  }

  const backup = snap.data() as BackupDocument;

  const bucket = getBucket();
  const file = bucket.file(backup.storagePath);

  const [contents] = await file.download();

  // Check if data is gzip compressed by looking for magic bytes (0x1f 0x8b)
  const isGzipped = contents.length >= 2 && contents[0] === 0x1f && contents[1] === 0x8b;

  let jsonString: string;
  if (isGzipped) {
    const decompressed = await gunzip(contents);
    jsonString = decompressed.toString("utf-8");
  } else {
    // Handle legacy uncompressed backups or auto-decompressed data
    jsonString = contents.toString("utf-8");
    logger.warn("Backup data was not gzip compressed", { uid });
  }

  logger.info("Backup loaded from Cloud Storage", {
    uid,
    version: backup.version,
  });

  return JSON.parse(jsonString);
}

/**
 * Get backup metadata only (no payload)
 */
export async function getBackupInfo(
  uid: string,
): Promise<{
  exists: boolean;
  version?: number;
  updatedAt?: Date;
  sizeBytes?: number;
}> {
  const backupRef = db
    .collection("users")
    .doc(uid)
    .collection("backup")
    .doc("current");

  const snap = await backupRef.get();
  if (!snap.exists) {
    return { exists: false };
  }

  const backup = snap.data() as BackupDocument;

  return {
    exists: true,
    version: backup.version,
    updatedAt: backup.updatedAt.toDate(),
    sizeBytes: backup.sizeBytes,
  };
}
</file>

<file path="functions/src/utils/errors.ts">
import { Response } from "express";
import { logger } from "firebase-functions/v2";

export class ApiError extends Error {
  constructor(
    public statusCode: number,
    message: string,
    public code?: string,
  ) {
    super(message);
    this.name = "ApiError";
  }
}

export function handleError(error: unknown, res: Response): void {
  if (error instanceof ApiError) {
    logger.warn(`API Error: ${error.message}`, { code: error.code });
    res.status(error.statusCode).json({
      success: false,
      error: error.message,
      code: error.code,
    });
    return;
  }

  if (error instanceof Error) {
    logger.error(`Unexpected error: ${error.message}`, { stack: error.stack });
    res.status(500).json({
      success: false,
      error: "Internal server error",
    });
    return;
  }

  logger.error("Unknown error type", { error });
  res.status(500).json({
    success: false,
    error: "Internal server error",
  });
}

// Common API error factories (lowercase to satisfy new-cap rule)
export const errors = {
  invalidRequest: (message: string) =>
    new ApiError(400, message, "INVALID_REQUEST"),
  deviceNotFound: () =>
    new ApiError(404, "Device not found", "DEVICE_NOT_FOUND"),
  imageTooLarge: (maxSize: number) =>
    new ApiError(
      413,
      `Image exceeds maximum size of ${maxSize / 1024 / 1024}MB`,
      "IMAGE_TOO_LARGE",
    ),
  unsupportedFormat: (formats: string[]) =>
    new ApiError(
      415,
      `Unsupported image format. Supported: ${formats.join(", ")}`,
      "UNSUPPORTED_FORMAT",
    ),
  analysisFailed: (reason: string) =>
    new ApiError(422, `Food analysis failed: ${reason}`, "ANALYSIS_FAILED"),
  notFood: (description?: string) =>
    new ApiError(
      422,
      description || "The image does not appear to contain food",
      "NOT_FOOD",
    ),
  imageTooBlurry: () =>
    new ApiError(
      422,
      "The image is too blurry or unclear to analyze",
      "IMAGE_TOO_BLURRY",
    ),
  multipleFoods: () =>
    new ApiError(
      422,
      "Multiple food items detected. Please capture one item at a time",
      "MULTIPLE_FOODS",
    ),
  lowConfidence: () =>
    new ApiError(
      422,
      "Could not confidently identify the food. Try a clearer photo",
      "LOW_CONFIDENCE",
    ),
  aiServiceError: () =>
    new ApiError(
      503,
      "AI service temporarily unavailable. Please try again",
      "AI_SERVICE_ERROR",
    ),
  aiConfigError: () =>
    new ApiError(
      500,
      "AI service configuration error",
      "AI_CONFIG_ERROR",
    ),
  parseError: () =>
    new ApiError(
      500,
      "Failed to parse AI response",
      "PARSE_ERROR",
    ),
  rateLimited: () =>
    new ApiError(429, "Too many requests", "RATE_LIMITED"),
  internalError: () =>
    new ApiError(500, "Internal server error", "INTERNAL_ERROR"),
  // Auth & Credits errors
  unauthorized: (message?: string) =>
    new ApiError(401, message || "Unauthorized", "UNAUTHORIZED"),
  insufficientCredits: () =>
    new ApiError(402, "Insufficient AI credits", "INSUFFICIENT_CREDITS"),
  backupNotFound: () =>
    new ApiError(404, "No backup found for this user", "BACKUP_NOT_FOUND"),
  storageError: (message?: string) =>
    new ApiError(500, message || "Storage operation failed", "STORAGE_ERROR"),
};
</file>

<file path="functions/package.json">
{
  "name": "weigh-backend-functions",
  "version": "1.0.0",
  "description": "Firebase Cloud Functions for weight-tracking mobile app",
  "main": "lib/index.js",
  "scripts": {
    "build": "tsc",
    "build:watch": "tsc --watch",
    "serve": "npm run build && firebase emulators:start --only functions",
    "shell": "npm run build && firebase functions:shell",
    "start": "npm run shell",
    "deploy": "firebase deploy --only functions",
    "logs": "firebase functions:log",
    "lint": "eslint --ext .ts src/",
    "lint:fix": "eslint --ext .ts src/ --fix"
  },
  "engines": {
    "node": "20"
  },
  "dependencies": {
    "busboy": "^1.6.0",
    "cors": "^2.8.5",
    "firebase-admin": "^12.7.0",
    "firebase-functions": "^6.1.2",
    "openai": "^4.77.0",
    "ulid": "^3.0.2",
    "zod": "^3.24.1"
  },
  "devDependencies": {
    "@types/busboy": "^1.5.4",
    "@types/cors": "^2.8.19",
    "@typescript-eslint/eslint-plugin": "^8.18.1",
    "@typescript-eslint/parser": "^8.18.1",
    "eslint": "^8.57.1",
    "eslint-config-google": "^0.14.0",
    "eslint-plugin-import": "^2.31.0",
    "typescript": "^5.7.2"
  },
  "private": true
}
</file>

<file path="firestore.indexes.json">
{
    "indexes": [
        {
            "collectionGroup": "events",
            "queryScope": "COLLECTION",
            "fields": [
                {
                    "fieldPath": "user_id",
                    "order": "ASCENDING"
                },
                {
                    "fieldPath": "event_name",
                    "order": "ASCENDING"
                },
                {
                    "fieldPath": "event_timestamp_utc",
                    "order": "DESCENDING"
                }
            ]
        },
        {
            "collectionGroup": "workflows",
            "queryScope": "COLLECTION",
            "fields": [
                {
                    "fieldPath": "status",
                    "order": "ASCENDING"
                },
                {
                    "fieldPath": "expiresAt",
                    "order": "ASCENDING"
                }
            ]
        }
    ],
    "fieldOverrides": []
}
</file>

<file path="functions/src/handlers/registerDevice.ts">
import { Request, Response } from "express";
import { logger } from "firebase-functions/v2";
import { upsertDevice } from "../services/firestore";
import { upsertUserProfile } from "../services/user";
import { trackEventAsync } from "../services/events";
import { deviceRegistrationSchema, validateInput } from "../utils/validation";
import { handleError, errors } from "../utils/errors";
import { EventName } from "../types/behavioral";
import { AuthenticatedRequest, verifyAuth } from "../middleware/auth";

export async function registerDevice(
  req: Request & AuthenticatedRequest,
  res: Response,
): Promise<void> {
  try {
    // Only allow POST
    if (req.method !== "POST") {
      res.status(405).json({
        success: false,
        error: "Method not allowed",
      });
      return;
    }

    // 1. VERIFY AUTH
    // This connects the request to the Firebase User (Anonymous or Gmail)
    await new Promise<void>((resolve, reject) => {
      verifyAuth(req, res, (err?: unknown) => {
        if (err) reject(err);
        else resolve();
      });
    });
    if (res.headersSent) return;

    const uid = req.uid!; // Securely obtained from token

    // 2. Validate input
    const validation = validateInput(deviceRegistrationSchema, req.body);
    if (!validation.success) {
      throw errors.invalidRequest(validation.error);
    }

    const { deviceId, fcmToken, platform, timezone, displayName } = validation.data;

    logger.info(`Registering device: ${deviceId} to User: ${uid}`);

    // 3. Upsert user profile (displayName, timezone)
    await upsertUserProfile(uid, { displayName, timezone });

    // 4. Upsert device (FCM only, no profile data)
    await upsertDevice(uid, deviceId, fcmToken, platform);

    // 5. Track Event (Now properly attributed to the UID)
    if (timezone) {
      trackEventAsync({
        eventName: EventName.DEVICE_REGISTERED,
        userId: uid, // Use actual UID now, not deviceId
        timestamp: new Date().toISOString(),
        timezone,
        platform,
        metadata: {
          timezone,
          platform,
          deviceId, // Keep deviceId in metadata for debugging
        },
      }).catch((err) => {
        logger.warn("Failed to track device registration event", { error: err });
      });
    }

    res.status(200).json({
      success: true,
      message: "Device registered successfully",
    });
  } catch (error) {
    handleError(error, res);
  }
}
</file>

<file path="functions/src/utils/validation.ts">
import { z } from "zod";

// Device registration validation schema
export const deviceRegistrationSchema = z.object({
  deviceId: z
    .string()
    .min(1, "deviceId is required")
    .max(256, "deviceId too long"),
  fcmToken: z
    .string()
    .min(1, "fcmToken is required")
    .max(4096, "fcmToken too long"),
  platform: z.enum(["ios", "android"], {
    errorMap: () => ({ message: "platform must be 'ios' or 'android'" }),
  }),
  timezone: z.string().min(1).optional(),
  displayName: z.string().max(100).optional(),
});

// Food analysis validation schema (deviceId now optional, auth provides uid)
export const foodAnalysisSchema = z.object({
  image: z
    .string()
    .min(1, "image is required")
    .optional(),
});

// Backup data validation schema
export const backupSchema = z.object({
  weightEntries: z.array(z.unknown()).optional(),
  foodLogs: z.array(z.unknown()).optional(),
  streaks: z.record(z.unknown()).optional(),
  metadata: z.record(z.unknown()).optional(),
});

// Type exports from schemas
export type DeviceRegistrationInput = z.infer<typeof deviceRegistrationSchema>;
export type FoodAnalysisInput = z.infer<typeof foodAnalysisSchema>;
export type BackupInput = z.infer<typeof backupSchema>;

// Validation helper
export function validateInput<T>(
  schema: z.ZodSchema<T>,
  data: unknown,
): { success: true; data: T } | { success: false; error: string } {
  const result = schema.safeParse(data);
  if (result.success) {
    return { success: true, data: result.data };
  }
  const errorMessage = result.error.errors
    .map((e) => `${e.path.join(".")}: ${e.message}`)
    .join(", ");
  return { success: false, error: errorMessage };
}
</file>

<file path="functions/src/api.ts">
import express, { Request, Response } from "express";
import cors from "cors";
import { latencyLogger } from "./middleware/latency";
import { analyzeFoodImage } from "./handlers/analyzeFoodImage";
import { createBackup, restoreBackup, getBackupStatus } from "./handlers/backup";
import { getCreditsHandler, getUserProfile } from "./handlers/credits";
import { registerDevice } from "./handlers/registerDevice";
import { quickScan } from "./handlers/quickScan";
import { logEvent } from "./handlers/events";
import {
  createWorkflow,
  resolveWorkflow,
  completeWorkflow,
} from "./handlers/workflow";

const app = express();

// Health check BEFORE heavy middleware (fast path)
app.get("/health", (_req: Request, res: Response) => {
  res.json({ status: "ok", version: "1.0.0" });
});

// Middleware
app.use(cors({ origin: true }));
app.use(express.json({ limit: "6mb" })); // Matches 5MB image limit + overhead
app.use(latencyLogger);

/**
 * Route Map (v1 - stable)
 * -----------------------
 * POST /register-device  - Device registration (auth required)
 * POST /analyze-food     - Food image analysis (auth required)
 * POST /quick-scan       - Quick food scan (auth required)
 * POST /events           - Event tracking (auth required)
 * POST /backup           - Create backup (auth required)
 * POST /restore          - Restore backup (auth required)
 * GET  /backup-status    - Backup metadata (auth required)
 * GET  /credits          - Credit balance (auth required)
 * GET  /user/me          - User profile (auth required)
 *
 * Workflow Routes (deferred deep linking)
 * ---------------------------------------
 * POST /workflows        - Create workflow (auth required)
 * GET  /workflows/:id    - Resolve workflow (public)
 * POST /workflows/:id/complete - Complete workflow (public)
 *
 * Route paths are considered stable for v1 and will not change
 * without version bump.
 */

// Public routes
app.post("/register-device", registerDevice);

// Authenticated routes (auth enforced in handlers via verifyAuth)
app.post("/analyze-food", analyzeFoodImage);
app.post("/quick-scan", quickScan);
app.post("/backup", createBackup);
app.post("/restore", restoreBackup);
app.get("/backup-status", getBackupStatus);
app.get("/credits", getCreditsHandler);
app.get("/user/me", getUserProfile);
app.post("/events", logEvent);

// Workflow routes (deferred deep linking)
app.post("/workflows", createWorkflow);
app.get("/workflows/:id", resolveWorkflow);
app.post("/workflows/:id/complete", completeWorkflow);

// 404 handler
app.use((_req: Request, res: Response) => {
  res.status(404).json({
    success: false,
    error: "Endpoint not found",
    code: "NOT_FOUND",
  });
});

export { app };
</file>

<file path="functions/src/handlers/sendDailyNudge.ts">
import { logger } from "firebase-functions/v2";
import { getActiveDevices } from "../services/firestore";
import { sendBatchNotifications, PreparedNotification, SendResult } from "../services/fcm";
import { resolveContextBatch } from "../services/user";
import { trackEventAsync } from "../services/events";
import { TemplateId, renderTemplate, getTemplate } from "../config/templates";
import { COLLECTIONS, LIMITS } from "../config/constants";
import { EventName } from "../types/behavioral";
import { getFirestore, Timestamp } from "firebase-admin/firestore";

const db = getFirestore();

// Chunk helper for batching
function chunk<T>(array: T[], size: number): T[][] {
  const chunks: T[][] = [];
  for (let i = 0; i < array.length; i += size) {
    chunks.push(array.slice(i, i + size));
  }
  return chunks;
}

// Get today's date in YYYY-MM-DD format for idempotency
function getActiveDate(): string {
  return new Date().toISOString().split("T")[0];
}

/**
 * Notification document structure
 */
interface NotificationDocument {
  notification_id: string;
  device_id: string;
  uid: string;
  notification_type: string;
  title: string;
  body: string;
  link: string;
  delivery_status: "success" | "failed";
  error_message?: string;
  sent_at: FirebaseFirestore.Timestamp;
}

/**
 * Log notification to 'notifications' collection
 */
async function logNotification(notification: NotificationDocument): Promise<void> {
  await db.collection(COLLECTIONS.NOTIFICATIONS).add(notification);
}

/**
 * Factory function that creates a nudge handler for a specific template.
 * Uses the new personalization pipeline:
 * 1. Select devices
 * 2. Batch UIDs
 * 3. Resolve context
 * 4. Render templates
 * 5. Prepare payloads
 * 6. Deliver
 * 7. Log results
 */
export function createNudgeHandler(templateId: TemplateId) {
  return async function sendNudge(): Promise<void> {
    const template = getTemplate(templateId);
    const activeDate = getActiveDate();

    logger.info(`Starting ${templateId} nudge job`, { link: template.link });

    try {
      // 1. Select all active devices
      const devices = await getActiveDevices();
      logger.info(`Found ${devices.length} active devices`);

      if (devices.length === 0) {
        logger.info("No active devices to notify");
        return;
      }

      // 2. Extract unique UIDs and batch them
      const uidToDevices = new Map<string, typeof devices>();
      for (const device of devices) {
        const existing = uidToDevices.get(device.uid) || [];
        existing.push(device);
        uidToDevices.set(device.uid, existing);
      }
      const uniqueUids = Array.from(uidToDevices.keys());
      const uidBatches = chunk(uniqueUids, LIMITS.FCM_BATCH_SIZE);

      const allResults: SendResult[] = [];

      // Process each UID batch
      for (const uidBatch of uidBatches) {
        // 3. Resolve personalization context for batch
        const contextMap = await resolveContextBatch(uidBatch);

        // 4 & 5. Render templates and prepare payloads
        const payloads: PreparedNotification[] = [];

        for (const uid of uidBatch) {
          const context = contextMap.get(uid)!;
          const rendered = renderTemplate(template, context);
          const userDevices = uidToDevices.get(uid) || [];

          for (const device of userDevices) {
            // Idempotent notification ID: prevents duplicates on job retry
            const notificationId = `${template.id}_${activeDate}_${uid}_${device.deviceId}`;

            payloads.push({
              fcmToken: device.fcmToken,
              title: rendered.title,
              body: rendered.body,
              notificationId,
              link: template.link,
              deviceId: device.deviceId,
              uid: device.uid,
            });
          }
        }

        // 6. Deliver batch
        const results = await sendBatchNotifications(payloads);
        allResults.push(...results);

        // 7. Log each notification result
        const logPromises = results.map(async (result) => {
          const payload = payloads.find((p) => p.notificationId === result.notificationId)!;
          const deliveryStatus = result.success ? "success" : "failed";

          // Log to 'notifications' collection
          const notificationDoc: NotificationDocument = {
            notification_id: result.notificationId,
            device_id: result.deviceId,
            uid: result.uid,
            notification_type: templateId,
            title: payload.title,
            body: payload.body,
            link: template.link,
            delivery_status: deliveryStatus,
            ...(result.error && { error_message: result.error }),
            sent_at: Timestamp.now(),
          };

          await logNotification(notificationDoc);

          // Track NOTIFICATION_DELIVERED event (fire-and-forget)
          trackEventAsync({
            eventName: EventName.NOTIFICATION_DELIVERED,
            userId: result.uid,
            timestamp: new Date().toISOString(),
            timezone: "UTC",
            platform: "ios", // Default, we may add platform to device doc later
            metadata: {
              notification_id: result.notificationId,
              notification_type: templateId,
              delivery_status: deliveryStatus,
              device_id: result.deviceId,
              ...(result.error && { error_message: result.error }),
            },
          }).catch((err) => {
            logger.warn("Failed to track notification event", {
              notificationId: result.notificationId,
              error: err,
            });
          });
        });

        await Promise.all(logPromises);
      }

      const successCount = allResults.filter((r) => r.success).length;
      logger.info(`${templateId} nudge complete: ${successCount}/${allResults.length} successful`);
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : "Unknown error";
      logger.error(`${templateId} nudge failed: ${errorMessage}`);
      throw error;
    }
  };
}

// Export handlers using new template IDs
export const sendDailyNudge = createNudgeHandler("WEIGHT_REMINDER_V1");
export const sendBreakfastNudge = createNudgeHandler("BREAKFAST_V1");
export const sendLunchNudge = createNudgeHandler("LUNCH_V1");
export const sendSnacksNudge = createNudgeHandler("SNACKS_V1");
export const sendDinnerNudge = createNudgeHandler("DINNER_V1");
export const sendEveningCheckinNudge = createNudgeHandler("EVENING_CHECKIN_V1");
</file>

<file path="functions/src/services/fcm.ts">
import { admin } from "./firestore";
import { logger } from "firebase-functions/v2";
import { LIMITS } from "../config/constants";

/**
 * Prepared notification payload - fully rendered, ready for delivery.
 * FCM service is a "dumb" transport layer - it just sends what it receives.
 */
export interface PreparedNotification {
  fcmToken: string;
  title: string;
  body: string;
  notificationId: string;
  link?: string;
  // Metadata for logging (not sent to FCM)
  deviceId: string;
  uid: string;
}

/**
 * Result of sending a notification.
 */
export interface SendResult {
  deviceId: string;
  uid: string;
  notificationId: string;
  success: boolean;
  error?: string;
}

/**
 * Send a single push notification via FCM.
 */
export async function sendPushNotification(
  fcmToken: string,
  title: string,
  body: string,
  notificationId: string,
  link?: string,
): Promise<{ success: boolean; error?: string }> {
  try {
    await admin.messaging().send({
      token: fcmToken,
      notification: {
        title,
        body,
      },
      data: {
        notification_id: notificationId,
        ...(link && { link }),
      },
      android: {
        priority: "high",
        notification: {
          channelId: "weight_reminders",
        },
      },
      apns: {
        payload: {
          aps: {
            sound: "default",
            badge: 1,
          },
        },
      },
    });
    return { success: true };
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : "Unknown error";
    logger.warn(`FCM send failed: ${errorMessage}`);
    return { success: false, error: errorMessage };
  }
}

/**
 * Send batch notifications with prepared payloads.
 * This is a pure transport layer - payloads are already rendered with personalization.
 *
 * @param payloads Array of fully prepared notification payloads
 * @returns Array of send results
 */
export async function sendBatchNotifications(
  payloads: PreparedNotification[],
): Promise<SendResult[]> {
  const results: SendResult[] = [];

  // Process in batches to respect FCM limits
  for (let i = 0; i < payloads.length; i += LIMITS.FCM_BATCH_SIZE) {
    const batch = payloads.slice(i, i + LIMITS.FCM_BATCH_SIZE);

    const batchPromises = batch.map(async (payload) => {
      const result = await sendPushNotification(
        payload.fcmToken,
        payload.title,
        payload.body,
        payload.notificationId,
        payload.link,
      );
      return {
        deviceId: payload.deviceId,
        uid: payload.uid,
        notificationId: payload.notificationId,
        success: result.success,
        error: result.error,
      };
    });

    const batchResults = await Promise.all(batchPromises);
    results.push(...batchResults);
  }

  const successCount = results.filter((r) => r.success).length;
  const failCount = results.length - successCount;
  logger.info(`Batch send complete: ${successCount} success, ${failCount} failed`);

  return results;
}
</file>

<file path="functions/src/types/index.ts">
// Type definitions for the weight-tracking backend

// Re-export vision schemas
export * from "./visionSchemas";
// Device registration types
export interface DeviceRegistrationRequest {
    deviceId: string;
    fcmToken: string;
    platform: "ios" | "android";
}

export interface DeviceDocument {
    deviceId: string;
    uid: string;
    fcmToken: string;
    platform: "ios" | "android";
    createdAt: FirebaseFirestore.Timestamp;
    lastSeenAt: FirebaseFirestore.Timestamp;
}

export interface DeviceRegistrationResponse {
    success: boolean;
    message: string;
}

// Nudge types
export interface NudgeDocument {
    deviceId: string;
    uid: string;
    sentAt: FirebaseFirestore.Timestamp;
    status: "success" | "failed";
    title: string;
    body: string;
    error?: string;
}

// Food analysis types
export interface FoodAnalysisRequest {
    deviceId: string;
    image?: string; // Base64 encoded image
}

export interface NutritionData {
    foodName: string;
    calories: number;
    protein: number;
    carbohydrates: number;
    fat: number;
    fiber: number;
    estimatedServingSize: string;
}

export interface FoodAnalysisResponse {
    success: boolean;
    nutrition?: NutritionData;
    error?: string;
}

// Quick scan response (lightweight food identification)
export interface QuickScanResponse {
    foodName: string;
    confidence: "high" | "medium" | "low";
    calories: number;
    message: string;
}

// API Error response
export interface ApiErrorResponse {
    success: false;
    error: string;
    code?: string;
}

// Backup payload types
// Matches backupSchema in utils/validation.ts
export interface BackupPayload {
    weightEntries?: unknown[];
    foodLogs?: unknown[];
    streaks?: Record<string, unknown>;
    metadata?: Record<string, unknown>;
}
</file>

<file path="functions/src/services/vision.ts">
import OpenAI from "openai";
import * as crypto from "crypto";
import { logger } from "firebase-functions/v2";
import { defineString } from "firebase-functions/params";
import {
  VisionPassResult,
  VisionErrorSchema,
  FoodAnalysisRecord,
  NutritionData,
  PerceptionResult,
  PerceptionResultSchema,
  NutritionResult,
  NutritionResultSchema,
  PerceptionItem,
} from "../types";
import { VISION_CONFIG, COLLECTIONS } from "../config/constants";
import { errors } from "../utils/errors";
import { db, admin } from "./firestore";

// Define the API key as a Firebase parameter
const openaiApiKey = defineString("OPENAI_API_KEY");

// =============================================================================
// 2-STAGE PROMPTS
// =============================================================================

/* eslint-disable max-len */

/**
 * Stage 1: Vision Perception
 * Only what requires pixels. Nothing else.
 */
const PERCEPTION_PROMPT = `You are a food perception system.

Task:
From the image, identify up to 5 distinct food items and estimate their
approximate edible weight in grams.

Rules:
- Focus on visual identification only.
- Be conservative with weight estimates.
- Do NOT estimate nutrition.
- Do NOT explain reasoning.
- Do NOT infer ingredients or cooking method.
- Output JSON only.

Response format:
{
  "items": [
    {
      "foodName": "string",
      "estimatedWeight_g": number,
      "confidence": number between 0 and 1
    }
  ]
}

Error format:
{
  "error": "description",
  "errorType": "NOT_FOOD" | "BLURRY" | "LOW_CONFIDENCE" | "MULTIPLE_ITEMS"
}`;

/**
 * Stage 2: Nutrition Reasoning (Text-only)
 * Statistical nutrition estimation from identified items.
 */
const NUTRITION_PROMPT = `You are a nutrition estimation system.

Given the following food items and their estimated weights,
estimate typical home-style nutrition values.

Rules:
- Use typical preparation assumptions.
- Be conservative.
- No explanations.
- Output JSON only.

Response format:
{
  "items": [
    {
      "foodName": "string",
      "calories": number,
      "protein": number,
      "carbohydrates": number,
      "fat": number,
      "fiber": number
    }
  ]
}`;

/* eslint-enable max-len */

// =============================================================================
// Utility Functions
// =============================================================================

/**
 * Compute SHA-256 hash of image with byte length salt for collision safety
 */
function computeImageHash(imageBase64: string): { hash: string; byteLength: number } {
  const buffer = Buffer.from(imageBase64, "base64");
  const byteLength = buffer.length;
  const saltedInput = `${imageBase64}:${byteLength}`;
  const hash = crypto.createHash("sha256").update(saltedInput).digest("hex");
  return { hash, byteLength };
}

/**
 * Clean markdown code blocks from LLM response
 */
function cleanJsonResponse(content: string): string {
  let clean = content.trim();
  if (clean.startsWith("```json")) {
    clean = clean.slice(7);
  }
  if (clean.startsWith("```")) {
    clean = clean.slice(3);
  }
  if (clean.endsWith("```")) {
    clean = clean.slice(0, -3);
  }
  return clean.trim();
}

/**
 * Normalize food name between stages
 * - lowercase
 * - trim
 * - basic plural handling
 */
function normalizeFoodName(name: string): string {
  let normalized = name.toLowerCase().trim();
  // Simple plural normalization
  if (normalized.endsWith("ies") && normalized.length > 4) {
    normalized = normalized.slice(0, -3) + "y";
  } else if (normalized.endsWith("es") && normalized.length > 3) {
    normalized = normalized.slice(0, -2);
  } else if (normalized.endsWith("s") && normalized.length > 2) {
    normalized = normalized.slice(0, -1);
  }
  return normalized;
}

// =============================================================================
// Error Handling
// =============================================================================

function handleAiError(errorMessage: string, errorType?: string): never {
  const lowerMessage = errorMessage.toLowerCase();

  if (errorType) {
    switch (errorType) {
    case "NOT_FOOD":
      throw errors.notFood(errorMessage);
    case "BLURRY":
      throw errors.imageTooBlurry();
    case "MULTIPLE_ITEMS":
      throw errors.multipleFoods();
    case "LOW_CONFIDENCE":
      throw errors.lowConfidence();
    default:
      throw errors.analysisFailed(errorMessage);
    }
  }

  if (lowerMessage.includes("not food") || lowerMessage.includes("no food")) {
    throw errors.notFood(errorMessage);
  }
  if (lowerMessage.includes("blurry") || lowerMessage.includes("unclear")) {
    throw errors.imageTooBlurry();
  }
  if (lowerMessage.includes("cannot identify") || lowerMessage.includes("not sure")) {
    throw errors.lowConfidence();
  }

  throw errors.analysisFailed(errorMessage);
}

// =============================================================================
// Stage 1: Vision Perception
// =============================================================================

interface PerceptionOutput {
  rawText: string;
  parsed: PerceptionResult;
  durationMs: number;
}

/**
 * Stage 1: Identify food items and estimate weights from image.
 * Uses vision model with tight token limit.
 */
async function runVisionPerception(
  openai: OpenAI,
  imageBase64: string,
): Promise<PerceptionOutput> {
  const startTime = Date.now();

  const response = await openai.chat.completions.create({
    model: VISION_CONFIG.MODEL,
    max_completion_tokens: VISION_CONFIG.PERCEPTION_MAX_TOKENS,
    messages: [
      {
        role: "user",
        content: [
          { type: "text", text: PERCEPTION_PROMPT },
          {
            type: "image_url",
            image_url: {
              url: `data:image/jpeg;base64,${imageBase64}`,
              detail: "low",
            },
          },
        ],
      },
    ],
  });

  const durationMs = Date.now() - startTime;
  const rawText = response.choices[0]?.message?.content;

  if (!rawText) {
    throw errors.aiServiceError();
  }

  const cleanContent = cleanJsonResponse(rawText);
  let parsed: unknown;

  try {
    parsed = JSON.parse(cleanContent);
  } catch {
    logger.error("Failed to parse perception response", { rawText });
    throw errors.parseError();
  }

  // Check for error response
  const errorResult = VisionErrorSchema.safeParse(parsed);
  if (errorResult.success) {
    handleAiError(errorResult.data.error, errorResult.data.errorType);
  }

  // Parse as perception result
  const successResult = PerceptionResultSchema.safeParse(parsed);
  if (!successResult.success) {
    logger.error("Perception response validation failed", {
      errors: successResult.error.issues,
      rawText,
    });
    throw errors.parseError();
  }

  logger.info("Stage 1 (Perception) complete", {
    itemCount: successResult.data.items.length,
    durationMs,
  });

  return { rawText, parsed: successResult.data, durationMs };
}

// =============================================================================
// Stage 2: Nutrition Reasoning (Text-only)
// =============================================================================

interface NutritionOutput {
  rawText: string;
  parsed: NutritionResult;
  durationMs: number;
}

/**
 * Stage 2: Estimate nutrition from identified food items.
 * Text-only model call - no image context.
 */
async function runNutritionText(
  openai: OpenAI,
  items: PerceptionItem[],
): Promise<NutritionOutput> {
  const startTime = Date.now();

  // Prepare input with normalized food names
  const input = items.map((item) => ({
    foodName: item.foodName,
    estimatedWeight_g: item.estimatedWeight_g,
  }));

  const response = await openai.chat.completions.create({
    model: VISION_CONFIG.TEXT_MODEL, // Explicitly mark as text-only
    max_completion_tokens: VISION_CONFIG.NUTRITION_MAX_TOKENS,
    messages: [
      {
        role: "user",
        content: `${NUTRITION_PROMPT}\n\nInput:\n${JSON.stringify(input, null, 2)}`,
      },
    ],
  });

  const durationMs = Date.now() - startTime;
  const rawText = response.choices[0]?.message?.content;

  if (!rawText) {
    throw errors.aiServiceError();
  }

  const cleanContent = cleanJsonResponse(rawText);
  let parsed: unknown;

  try {
    parsed = JSON.parse(cleanContent);
  } catch {
    logger.error("Failed to parse nutrition response", { rawText });
    throw errors.parseError();
  }

  // Parse as nutrition result
  const successResult = NutritionResultSchema.safeParse(parsed);
  if (!successResult.success) {
    logger.error("Nutrition response validation failed", {
      errors: successResult.error.issues,
      rawText,
    });
    throw errors.parseError();
  }

  logger.info("Stage 2 (Nutrition) complete", {
    itemCount: successResult.data.items.length,
    durationMs,
  });

  return { rawText, parsed: successResult.data, durationMs };
}

// =============================================================================
// Confidence Gating
// =============================================================================

/**
 * Gate Stage 2 execution based on perception confidence.
 * Throws LOW_CONFIDENCE if any item is below threshold.
 */
function validatePerceptionConfidence(items: PerceptionItem[]): void {
  const minConfidence = Math.min(...items.map((i) => i.confidence));

  if (minConfidence < VISION_CONFIG.MIN_CONFIDENCE) {
    logger.warn("Perception confidence too low, aborting Stage 2", {
      minConfidence,
      threshold: VISION_CONFIG.MIN_CONFIDENCE,
    });
    throw errors.lowConfidence();
  }
}

// =============================================================================
// Merge Results to VisionPassResult (backward compatibility)
// =============================================================================

/**
 * Merge perception and nutrition outputs into VisionPassResult format.
 * This maintains backward compatibility with existing persistence and aggregation.
 */
function mergeToVisionPassResult(
  perception: PerceptionResult,
  nutrition: NutritionResult,
): VisionPassResult {
  // Create a map of normalized food names to nutrition data
  const nutritionMap = new Map<string, NutritionResult["items"][0]>();
  for (const item of nutrition.items) {
    nutritionMap.set(normalizeFoodName(item.foodName), item);
  }

  // Merge perception items with nutrition data
  const items = perception.items.map((pItem) => {
    const normalizedName = normalizeFoodName(pItem.foodName);
    const nItem = nutritionMap.get(normalizedName);

    // Default nutrition if not found (shouldn't happen but be safe)
    const calories = nItem?.calories ?? 0;
    const protein = nItem?.protein ?? 0;
    const carbohydrates = nItem?.carbohydrates ?? 0;
    const fat = nItem?.fat ?? 0;
    const fiber = nItem?.fiber ?? 0;

    return {
      foodName: pItem.foodName,
      estimatedWeight_g: pItem.estimatedWeight_g,
      calories,
      protein,
      carbohydrates,
      fat,
      fiber,
      // Placeholder canonical data (not used in 2-stage mode)
      _canonical: {
        cuisine: "unknown",
        baseIngredients: [],
        cookingMethod: "unknown",
        density: "medium" as const,
        moisture: "moist" as const,
        processingLevel: "minimal" as const,
      },
      _debug: {
        confidence: pItem.confidence,
        visualCues: [],
      },
    };
  });

  const totalWeight = items.reduce((sum, i) => sum + i.estimatedWeight_g, 0);
  const totalCalories = items.reduce((sum, i) => sum + i.calories, 0);

  return {
    items,
    totalWeight_g: totalWeight,
    totalCalories,
  };
}

// =============================================================================
// Persistence
// =============================================================================

async function persistAnalysis(record: FoodAnalysisRecord): Promise<void> {
  try {
    await db.collection(COLLECTIONS.FOOD_ANALYSES).add({
      ...record,
      createdAt: admin.firestore.Timestamp.fromDate(record.createdAt),
    });
    logger.info("Persisted food analysis", {
      imageHash: record.imageHash,
      status: record.status,
      itemCount: record.finalResult.items.length,
    });
  } catch (err) {
    logger.error("Failed to persist food analysis", { error: err });
    // Don't throw - persistence failure shouldn't block response
  }
}

// =============================================================================
// Legacy Aggregation (Backward Compatibility)
// =============================================================================

function aggregateToLegacy(result: VisionPassResult): NutritionData {
  const totalProtein = result.items.reduce((sum, i) => sum + i.protein, 0);
  const totalCarbs = result.items.reduce((sum, i) => sum + i.carbohydrates, 0);
  const totalFat = result.items.reduce((sum, i) => sum + i.fat, 0);
  const totalFiber = result.items.reduce((sum, i) => sum + i.fiber, 0);

  const foodName = result.items.length === 1 ?
    result.items[0].foodName :
    "Mixed meal";

  return {
    foodName,
    calories: result.totalCalories,
    protein: Math.round(totalProtein * 10) / 10,
    carbohydrates: Math.round(totalCarbs * 10) / 10,
    fat: Math.round(totalFat * 10) / 10,
    fiber: Math.round(totalFiber * 10) / 10,
    estimatedServingSize: `${result.totalWeight_g}g`,
  };
}

// =============================================================================
// Main Entry Point: 2-Stage Pipeline
// =============================================================================

export async function analyzeFood(imageBase64: string): Promise<NutritionData> {
  const startTime = Date.now();
  const apiKey = openaiApiKey.value();

  if (!apiKey) {
    throw errors.aiConfigError();
  }

  const openai = new OpenAI({ apiKey });
  const { hash: imageHash, byteLength: imageByteLength } = computeImageHash(imageBase64);

  logger.info("Starting 2-stage food analysis", { imageHash });

  // ==========================================================================
  // Stage 1: Vision Perception
  // ==========================================================================
  let perception: PerceptionOutput;
  try {
    perception = await runVisionPerception(openai, imageBase64);
  } catch (err) {
    logger.error("Stage 1 (Perception) failed", { error: err });
    throw err;
  }

  // ==========================================================================
  // Confidence Gate
  // ==========================================================================
  validatePerceptionConfidence(perception.parsed.items);

  // ==========================================================================
  // Stage 2: Nutrition Reasoning (Text-only)
  // ==========================================================================
  let nutrition: NutritionOutput;
  try {
    nutrition = await runNutritionText(openai, perception.parsed.items);
  } catch (err) {
    logger.error("Stage 2 (Nutrition) failed", { error: err });
    throw err;
  }

  // ==========================================================================
  // Merge Results
  // ==========================================================================
  const finalResult = mergeToVisionPassResult(perception.parsed, nutrition.parsed);
  const totalDurationMs = Date.now() - startTime;

  logger.info("2-stage analysis complete", {
    itemCount: finalResult.items.length,
    totalCalories: finalResult.totalCalories,
    perceptionMs: perception.durationMs,
    nutritionMs: nutrition.durationMs,
    totalMs: totalDurationMs,
  });

  // ==========================================================================
  // Persist Analysis Record
  // ==========================================================================
  const record: FoodAnalysisRecord = {
    imageHash,
    imageByteLength,
    model: VISION_CONFIG.MODEL,
    promptVersion: VISION_CONFIG.PROMPT_VERSION,

    // Stage 1: Perception
    perceptionRawText: perception.rawText,
    perceptionParsed: perception.parsed,
    perceptionDurationMs: perception.durationMs,

    // Stage 2: Nutrition
    nutritionRawText: nutrition.rawText,
    nutritionParsed: nutrition.parsed,
    nutritionDurationMs: nutrition.durationMs,

    // Final result
    status: "TWO_STAGE",
    finalResult,
    createdAt: new Date(),
    durationMs: totalDurationMs,
  };

  await persistAnalysis(record);

  // Aggregate to legacy format for backward compatibility
  return aggregateToLegacy(finalResult);
}

// =============================================================================
// Quick Scan: Single-Stage Lightweight Analysis
// =============================================================================

const DAILY_CALORIE_TARGET = 2000;
const AVG_KCAL_PER_GRAM = 1.5; // Conservative average for mixed foods

/**
 * Map numeric confidence to categorical level
 */
function mapConfidenceLevel(confidence: number): "high" | "medium" | "low" {
  if (confidence >= 0.8) return "high";
  if (confidence >= 0.6) return "medium";
  return "low";
}

/**
 * Generate one-liner message about calorie percentage
 */
function generateCalorieMessage(calories: number): string {
  const percentage = Math.round((calories / DAILY_CALORIE_TARGET) * 100);
  return `That's ${percentage}% of a typical daily target`;
}

/**
 * Quick food scan - lightweight single-stage analysis
 * Returns simplified results: food name, confidence, estimated calories, one-liner
 *
 * Uses only Stage 1 (perception) for speed.
 * Does NOT persist to Firestore.
 */
export async function quickAnalyzeFood(imageBase64: string): Promise<{
  foodName: string;
  confidence: "high" | "medium" | "low";
  calories: number;
  message: string;
}> {
  const startTime = Date.now();
  const apiKey = openaiApiKey.value();

  if (!apiKey) {
    throw errors.aiConfigError();
  }

  const openai = new OpenAI({ apiKey });
  const { hash: imageHash } = computeImageHash(imageBase64);

  logger.info("Starting quick food scan", { imageHash });

  // Run Stage 1 only (perception)
  const perception = await runVisionPerception(openai, imageBase64);

  // Aggregate items if multiple detected
  const items = perception.parsed.items;
  const totalWeight = items.reduce((sum, i) => sum + i.estimatedWeight_g, 0);
  const avgConfidence = items.reduce((sum, i) => sum + i.confidence, 0) / items.length;

  // Generate food name
  const foodName = items.length === 1 ?
    items[0].foodName :
    items.map((i) => i.foodName).join(" + ");

  // Rough calorie estimate based on weight
  const calories = Math.round(totalWeight * AVG_KCAL_PER_GRAM);

  const durationMs = Date.now() - startTime;

  logger.info("Quick scan complete", {
    foodName,
    calories,
    confidence: mapConfidenceLevel(avgConfidence),
    durationMs,
  });

  return {
    foodName,
    confidence: mapConfidenceLevel(avgConfidence),
    calories,
    message: generateCalorieMessage(calories),
  };
}
</file>

<file path="functions/src/config/constants.ts">
// Configuration constants

export const COLLECTIONS = {
  DEVICES: "devices",
  NUDGES: "nudges",
  FOOD_ANALYSES: "food_analyses",
  EVENTS: "events",
  USERS: "users",
  NOTIFICATIONS: "notifications",
} as const;

export const LIMITS = {
  MAX_IMAGE_SIZE_BYTES: 5 * 1024 * 1024, // 5MB
  DEVICE_ACTIVE_DAYS: 30, // Consider device active if seen within this many days
  FCM_BATCH_SIZE: 500, // Max devices per FCM batch
} as const;

export const NUDGE_CONFIG = {
  DEFAULT_TITLE: "Time to log your weight! ‚öñÔ∏è",
  DEFAULT_BODY: "Consistency is key! Take a moment to log your weight today.",
} as const;

// NUDGE_TYPES moved to config/templates.ts as TEMPLATES
// Legacy mapping for backward compatibility during migration
export const LEGACY_NUDGE_TYPE_TO_TEMPLATE = {
  WEIGHT_REMINDER: "WEIGHT_REMINDER_V1",
  BREAKFAST: "BREAKFAST_V1",
  LUNCH: "LUNCH_V1",
  SNACKS: "SNACKS_V1",
  DINNER: "DINNER_V1",
  EVENING_CHECKIN: "EVENING_CHECKIN_V1",
} as const;

export const VISION_CONFIG = {
  MODEL: "gpt-4o",
  TEXT_MODEL: "gpt-4o", // Text-only model for Stage 2 (no vision capability needed)
  PERCEPTION_MAX_TOKENS: 384, // Stage 1: tight limit for perception-only
  NUTRITION_MAX_TOKENS: 512, // Stage 2: text-only nutrition estimation
  MAX_TOKENS: 2048, // Legacy: single-pass mode
  TIMEOUT_MS: 60000,
  SUPPORTED_FORMATS: ["image/jpeg", "image/png", "image/webp"],
  PROMPT_VERSION: "vision_v4_2stage",
  MIN_CONFIDENCE: 0.6, // Gate Stage 2 if perception confidence is below this
} as const;

export const FUNCTION_CONFIG = {
  REGION: "us-central1",
  TIMEOUT_SECONDS: 60,
  MEMORY: "256MiB" as const,
  ANALYSIS_MEMORY: "512MiB" as const,
} as const;

export const BACKUP_CONFIG = {
  STORAGE_BUCKET: process.env.STORAGE_BUCKET || "",
  STORAGE_PATH_PREFIX: "users",
  BACKUP_FILENAME: "current.gz",
} as const;
</file>

<file path="functions/src/index.ts">
import { onRequest } from "firebase-functions/v2/https";
import { onSchedule } from "firebase-functions/v2/scheduler";
import { setGlobalOptions } from "firebase-functions/v2";
import { initializeApp, getApps } from "firebase-admin/app";
import { createNudgeHandler } from "./handlers/sendDailyNudge";
import { app } from "./api";
import { FUNCTION_CONFIG } from "./config/constants";

// Initialize Firebase Admin SDK (only if not already initialized)
if (getApps().length === 0) {
  initializeApp();
}

// Set global options for all functions
setGlobalOptions({
  region: FUNCTION_CONFIG.REGION,
  timeoutSeconds: FUNCTION_CONFIG.TIMEOUT_SECONDS,
});

/**
 * Consolidated API Endpoint
 *
 * Single Express app serving all HTTP routes:
 * - POST /register-device  (public)
 * - POST /analyze-food     (auth)
 * - POST /quick-scan       (auth)
 * - POST /backup           (auth)
 * - POST /restore          (auth)
 * - GET  /backup-status    (auth)
 * - GET  /credits          (auth)
 * - GET  /user/me          (auth)
 * - GET  /health           (public)
 *
 * invoker: 'public' is safe because all protected routes
 * enforce Firebase Auth via verifyAuth middleware.
 */
export const api = onRequest(
  {
    memory: FUNCTION_CONFIG.ANALYSIS_MEMORY, // 512MiB for vision workload
    timeoutSeconds: 60,
    invoker: "public",
  },
  app,
);

// =============================================================================
// Scheduled Push Notifications (IST times)
// =============================================================================

const SCHEDULE_CONFIG = {
  timeZone: "Asia/Kolkata",
  memory: FUNCTION_CONFIG.MEMORY,
} as const;

/**
 * Weight Reminder - 7:30 AM IST
 * Opens: platewise://entry
 */
export const weightReminder = onSchedule(
  { schedule: "30 7 * * *", ...SCHEDULE_CONFIG },
  createNudgeHandler("WEIGHT_REMINDER_V1"),
);

/**
 * Breakfast Reminder - 8:30 AM IST
 * Opens: platewise://food/capture
 */
export const breakfastReminder = onSchedule(
  { schedule: "30 8 * * *", ...SCHEDULE_CONFIG },
  createNudgeHandler("BREAKFAST_V1"),
);

/**
 * Lunch Reminder - 1:00 PM IST
 * Opens: platewise://food/capture
 */
export const lunchReminder = onSchedule(
  { schedule: "0 13 * * *", ...SCHEDULE_CONFIG },
  createNudgeHandler("LUNCH_V1"),
);

/**
 * Snacks Reminder - 5:00 PM IST
 * Opens: platewise://food/capture
 */
export const snacksReminder = onSchedule(
  { schedule: "0 17 * * *", ...SCHEDULE_CONFIG },
  createNudgeHandler("SNACKS_V1"),
);

/**
 * Dinner Reminder - 8:30 PM IST
 * Opens: platewise://food/capture
 */
export const dinnerReminder = onSchedule(
  { schedule: "30 20 * * *", ...SCHEDULE_CONFIG },
  createNudgeHandler("DINNER_V1"),
);

/**
 * Evening Check-in - 9:30 PM IST
 * Opens: platewise://dashboard
 */
export const eveningCheckin = onSchedule(
  { schedule: "30 21 * * *", ...SCHEDULE_CONFIG },
  createNudgeHandler("EVENING_CHECKIN_V1"),
);
</file>

<file path="integration.md">
# Weigh Backend API Integration Guide

> **Version:** 2.1 (Consolidated API)  
> **Model:** GPT-5.2  
> **Last Updated:** 2026-01-06

---

## Table of Contents

1. [Authentication](#authentication)
2. [Base URL & Region](#base-url--region)
3. [Common Response Structures](#common-response-structures)
4. [Endpoints](#endpoints)
   - [Food Image Analysis](#1-food-image-analysis)
   - [Quick Food Scan](#2-quick-food-scan)
   - [User Profile](#3-user-profile)
   - [Credits](#4-credits)
   - [Backup](#5-backup)
   - [Restore](#6-restore)
   - [Backup Status](#7-backup-status)
   - [Device Registration](#8-device-registration)
   - [Workflows (Deferred Deep Links)](#10-workflows-deferred-deep-links)
5. [Error Codes](#error-codes)
6. [Rate Limiting & Credits](#rate-limiting--credits)
7. [Internal Architecture](#internal-architecture-for-advanced-integrators)

---

## Authentication

All protected endpoints require a **Firebase ID Token** sent via the `Authorization` header.

```http
Authorization: Bearer <firebase_id_token>
```

### Authentication Flow

1. **Anonymous Auth**: Users start with anonymous Firebase Auth
2. **Link Account**: Later link to Google/Email for data persistence
3. **All data is keyed by `uid`** ‚Äî survives reinstalls when signed in

### How to Obtain a Token

```typescript
// Firebase Web/React Native SDK
import { getAuth } from "firebase/auth";

const auth = getAuth();
const user = auth.currentUser;
const idToken = await user.getIdToken();

// Standard headers for all authenticated requests
const headers = {
  'Content-Type': 'application/json',
  'Authorization': `Bearer ${await auth.currentUser?.getIdToken()}`
};
```

```swift
// Firebase iOS SDK
Auth.auth().currentUser?.getIDToken { token, error in
    // Use token
}
```

### Token Expiration

- Firebase ID tokens expire after **1 hour**
- Refresh automatically using `getIdToken(forceRefresh: true)`

---

## Base URL & Region

### Production Base URL

```
https://api-<deployment-hash>-uc.a.run.app
```

> [!IMPORTANT]
> All endpoints now use a **single consolidated API**. Replace the placeholder with your actual deployed URL.

### Route Map

| Method | Route | Auth | Description |
|--------|-------|------|-------------|
| GET | `/health` | No | Health check |
| POST | `/register-device` | Yes | Device registration |
| POST | `/analyze-food` | Yes | Food image analysis |
| POST | `/quick-scan` | Yes | Quick food identification |
| POST | `/events` | Yes | Event tracking |
| POST | `/backup` | Yes | Create backup |
| POST | `/restore` | Yes | Restore backup |
| GET | `/backup-status` | Yes | Backup metadata |
| GET | `/credits` | Yes | Credit balance |
| GET | `/user/me` | Yes | User profile |
| POST | `/workflows` | Yes | Create workflow (deferred deep link) |
| GET | `/workflows/:id` | No | Resolve workflow |
| POST | `/workflows/:id/complete` | No | Complete workflow |

> Route paths are stable for v2.x and will not change without a major version bump.

---

## Common Response Structures

### Success Response

```json
{
  "success": true,
  // ... endpoint-specific fields
}
```

### Error Response

```json
{
  "success": false,
  "error": "Human-readable error message",
  "code": "ERROR_CODE"
}
```

---

## TypeScript Interfaces

Ready-to-use types for frontend integration:

```typescript
// Common Response Wrapper
interface ApiResponse<T> {
  success: boolean;
  message?: string;
  error?: string;
  code?: string;
  data?: T;
}

// Food Analysis Response
interface NutritionData {
  foodName: string;
  calories: number;
  protein: number;
  carbohydrates: number;
  fat: number;
  fiber: number;
  estimatedServingSize: string;
}

interface FoodAnalysisResponse {
  success: boolean;
  nutrition: NutritionData;
  creditsRemaining: number;
}

// User Profile
interface UserProfile {
  uid: string;
  aiCredits: number;
  totalGranted: number;
  totalUsed: number;
  createdAt: string;      // ISO 8601
  lastActiveAt: string;   // ISO 8601
}

// Backup Data
interface BackupPayload {
  weightEntries?: unknown[];
  foodLogs?: unknown[];
  streaks?: Record<string, unknown>;
  metadata?: Record<string, unknown>;
}

// Backup Status
interface BackupStatus {
  exists: boolean;
  lastModified?: string;  // ISO 8601
  sizeBytes?: number;
}

// Event Tracking
type EventName = 
  | 'WEIGHT_LOGGED'
  | 'FOOD_ANALYZED'
  | 'DEVICE_REGISTERED'
  | 'NOTIFICATION_DELIVERED'
  | 'NOTIFICATION_RECEIVED'
  | 'NOTIFICATION_OPENED'
  | 'INTENT_CAPTURED'
  | 'INTENT_CLOSED';

interface EventRequest {
  eventId: string;        // UUID v4 (client-generated)
  eventName: EventName;
  timestamp: string;      // ISO 8601
  timezone: string;       // IANA timezone
  sessionId: string;      // UUID v4 (app-generated on launch)
  platform: 'ios' | 'android';
  metadata: Record<string, unknown>;
}

interface EventResponse {
  success: boolean;
  status: 'created' | 'duplicate';
  eventId: string;
}

// Weight Logged Event Metadata
interface WeightLoggedMetadata {
  weight_value: number;
  unit: 'kg' | 'lbs';
  source: 'manual' | 'auto';
}

// Intent Event Metadata
interface IntentCapturedMetadata {
  intent_type: string;
  expected_duration: number; // minutes
}

interface IntentClosedMetadata {
  intent_type: string;
  outcome: 'completed' | 'abandoned' | 'expired';
  actual_duration: number;   // minutes
  expected_duration: number; // minutes
}
```

---

## Endpoints

### 1. Food Image Analysis

Analyzes a food image and returns nutritional information.

> **Auth Required:** Yes  
> **Credits:** Deducts 1 credit per analysis  
> **Method:** `POST`

#### Request Options

**Option A: Multipart Form Data**

```http
POST /analyzeFoodImageFunction
Authorization: Bearer <token>
Content-Type: multipart/form-data

--boundary
Content-Disposition: form-data; name="image"; filename="food.jpg"
Content-Type: image/jpeg

<binary image data>
--boundary--
```

**Option B: JSON with Base64**

```http
POST /analyzeFoodImageFunction
Authorization: Bearer <token>
Content-Type: application/json

{
  "image": "<base64_encoded_image>"
}
```

#### Image Constraints

| Constraint | Value |
|------------|-------|
| Max size | 5 MB |
| Supported formats | `image/jpeg`, `image/png`, `image/webp` |
| Recommended | JPEG, < 2MB for optimal speed |

#### Code Example

```typescript
const API_BASE = 'https://api-<deployment-hash>-uc.a.run.app';

const analyzeFood = async (base64Image: string) => {
  const response = await fetch(
    `${API_BASE}/analyze-food`,
    {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${await getIdToken()}`
      },
      body: JSON.stringify({ image: base64Image }),
    }
  );
  return response.json(); // { success, nutrition, creditsRemaining }
};
```

#### Response

```json
{
  "success": true,
  "nutrition": {
    "foodName": "Grilled Chicken Salad",
    "calories": 350,
    "protein": 28.5,
    "carbohydrates": 15.2,
    "fat": 18.3,
    "fiber": 4.5,
    "estimatedServingSize": "285g"
  },
  "creditsRemaining": 14
}
```

**Nutrition Field Units:**

| Field | Unit |
|-------|------|
| `calories` | kcal |
| `protein` | grams |
| `carbohydrates` | grams |
| `fat` | grams |
| `fiber` | grams |

> All numeric nutrition values are rounded to 1 decimal place (integers for calories).

#### Latency Expectations

| Scenario | Typical Latency |
|----------|----------------|
| Single-pass (most common) | ~700‚Äì900 ms |
| Two-pass (rare) | ~1.2‚Äì1.5 s |

#### Multi-Item Behavior

When multiple food items are detected:

| Field | Behavior |
|-------|----------|
| `foodName` | Set to `"Mixed meal"` |
| `calories` | Sum of all items |
| `protein`, `carbohydrates`, `fat`, `fiber` | Sum of all items |
| `estimatedServingSize` | Total weight in grams (e.g., `"450g"`) |

#### Example: Multi-Item Response

```json
{
  "success": true,
  "nutrition": {
    "foodName": "Mixed meal",
    "calories": 720,
    "protein": 45.2,
    "carbohydrates": 65.8,
    "fat": 28.5,
    "fiber": 8.2,
    "estimatedServingSize": "520g"
  },
  "creditsRemaining": 13
}
```

---

### 2. Quick Food Scan

Lightweight food identification that returns simplified results for quick feedback.

> **Auth Required:** Yes  
> **Credits:** Deducts 1 credit per scan  
> **Method:** `POST`

#### Request Options

Same as [Food Image Analysis](#1-food-image-analysis) ‚Äî supports both multipart and JSON with base64.

#### Response

```json
{
  "success": true,
  "foodName": "Grilled Chicken Sandwich",
  "confidence": "high",
  "calories": 450,
  "message": "That's 22% of a typical daily target",
  "creditsRemaining": 14
}
```

#### Response Fields

| Field | Type | Description |
|-------|------|-------------|
| `foodName` | string | Identified food name (or combined names if multiple items) |
| `confidence` | enum | `"high"`, `"medium"`, or `"low"` |
| `calories` | number | Rough calorie estimate based on portion size |
| `message` | string | Human-readable one-liner about calorie percentage |

#### Confidence Levels

| Level | Confidence Score | Meaning |
|-------|-----------------|---------|
| `high` | ‚â• 80% | Clear identification |
| `medium` | 60‚Äì79% | Reasonable guess |
| `low` | < 60% | Uncertain identification |

#### Latency Expectations

| Scenario | Typical Latency |
|----------|----------------|
| Single item | ~500‚Äì700 ms |
| Multiple items | ~600‚Äì800 ms |

> [!NOTE]
> Quick scan is faster than full analysis because it only runs a single perception stage (no nutrition reasoning).

#### Code Example

```typescript
const quickScanFood = async (base64Image: string) => {
  const response = await fetch(
    `${API_BASE}/quick-scan`,
    {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${await getIdToken()}`
      },
      body: JSON.stringify({ image: base64Image }),
    }
  );
  return response.json();
  // { success, foodName, confidence, calories, message, creditsRemaining }
};
```

#### Use Cases

- **Quick calorie check** ‚Äî Get a rough sense before deciding to eat
- **Food logging preview** ‚Äî Show user what will be logged before committing
- **Gamification** ‚Äî Quick feedback for streak-based features

---

### 3. User Profile

Returns the authenticated user's profile including credit information.

> **Auth Required:** Yes  
> **Method:** `GET`

```http
GET /userProfileFunction
Authorization: Bearer <token>
```

#### Response

```json
{
  "success": true,
  "user": {
    "uid": "abc123xyz",
    "aiCredits": 15,
    "totalGranted": 20,
    "totalUsed": 5,
    "createdAt": "2026-01-01T10:30:00.000Z",
    "lastActiveAt": "2026-01-01T12:15:00.000Z"
  }
}
```

| Field | Type | Description |
|-------|------|-------------|
| `uid` | string | Firebase user ID |
| `aiCredits` | number | Current available credits |
| `totalGranted` | number | Total credits ever granted (free + purchased) |
| `totalUsed` | number | Total credits consumed |
| `createdAt` | ISO 8601 | Account creation timestamp |
| `lastActiveAt` | ISO 8601 | Last API activity timestamp |

#### Code Example

```typescript
const getUserProfile = async () => {
  const res = await fetch(
    `${API_BASE}/user/me`,
    {
      headers: { 'Authorization': `Bearer ${await getIdToken()}` }
    }
  );
  return res.json(); // { success, user: UserProfile }
};
```

---

### 4. Credits

Returns only the credit balance (lightweight alternative to full profile).

> **Auth Required:** Yes  
> **Method:** `GET`

```http
GET /creditsFunction
Authorization: Bearer <token>
```

#### Response

```json
{
  "success": true,
  "credits": 15
}
```

#### Code Example

```typescript
const getCredits = async () => {
  const res = await fetch(
    `${API_BASE}/credits`,
    {
      headers: { 'Authorization': `Bearer ${await getIdToken()}` }
    }
  );
  return res.json(); // { success, credits: number }
};
```

---

### 5. Backup

Saves user data to cloud storage.

> **Auth Required:** Yes  
> **Method:** `POST`

```http
POST /backupFunction
Authorization: Bearer <token>
Content-Type: application/json
```

#### Request Body

```json
{
  "weightEntries": [
    { "date": "2026-01-01", "weight": 72.5, "unit": "kg" }
  ],
  "foodLogs": [
    { "date": "2026-01-01", "calories": 2100 }
  ],
  "streaks": {
    "currentStreak": 5,
    "longestStreak": 15
  },
  "metadata": {
    "appVersion": "2.1.0",
    "lastSyncedAt": "2026-01-01T12:00:00Z"
  }
}
```

All fields are optional. The payload is stored as-is.

#### Response

```json
{
  "success": true,
  "message": "Backup saved successfully"
}
```

#### Code Example

```typescript
const createBackup = async (data: BackupPayload) => {
  const res = await fetch(
    `${API_BASE}/backup`,
    {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${await getIdToken()}`
      },
      body: JSON.stringify(data),
    }
  );
  return res.json(); // { success, message }
};
```

---

### 6. Restore

Retrieves the most recent backup.

> **Auth Required:** Yes  
> **Method:** `POST`

```http
POST /restoreFunction
Authorization: Bearer <token>
```

#### Response

```json
{
  "success": true,
  "data": {
    "weightEntries": [...],
    "foodLogs": [...],
    "streaks": {...},
    "metadata": {...}
  }
}
```

#### Code Example

```typescript
const restoreBackup = async () => {
  const res = await fetch(
    `${API_BASE}/restore`,
    {
      method: 'POST',
      headers: { 'Authorization': `Bearer ${await getIdToken()}` }
    }
  );
  return res.json(); // { success, data: BackupPayload }
};
```

---

### 7. Backup Status

Check if a backup exists and get metadata.

> **Auth Required:** Yes  
> **Method:** `GET`

```http
GET /backupStatusFunction
Authorization: Bearer <token>
```

#### Response (Backup Exists)

```json
{
  "success": true,
  "exists": true,
  "lastModified": "2026-01-01T12:00:00Z",
  "sizeBytes": 4523
}
```

#### Response (No Backup)

```json
{
  "success": true,
  "exists": false
}
```

#### Code Example

```typescript
const getBackupStatus = async () => {
  const res = await fetch(
    `${API_BASE}/backup-status`,
    {
      headers: { 'Authorization': `Bearer ${await getIdToken()}` }
    }
  );
  return res.json(); // { success, exists, lastModified?, sizeBytes? }
};
```

---

### 8. Device Registration

Registers a device for push notifications and links it to the authenticated user.

> **Auth Required:** Yes  
> **Method:** `POST`

> [!IMPORTANT]
> **Breaking Change (v2.2):** This endpoint now requires authentication. The device is linked to the Firebase user (`uid`) to enable user-level notification tracking and account recovery.

```http
POST /register-device
Authorization: Bearer <firebase_id_token>
Content-Type: application/json
```

#### Request Body

```json
{
  "deviceId": "unique-device-identifier",
  "fcmToken": "firebase-cloud-messaging-token",
  "platform": "ios",
  "timezone": "Asia/Kolkata",
  "displayName": "Ronak"
}
```

| Field | Type | Constraints |
|-------|------|-------------|
| `deviceId` | string | 1-256 characters |
| `fcmToken` | string | 1-4096 characters |
| `platform` | enum | `"ios"` or `"android"` |
| `timezone` | string | Optional. IANA timezone (e.g., `"Asia/Kolkata"`) |
| `displayName` | string | Optional. Max 100 characters. Used for personalized notifications |

> [!NOTE]
> `displayName` and `timezone` are stored on the **user profile** (not the device) to enable personalized notifications like *"Good morning, Ronak!"*

#### Response

```json
{
  "success": true,
  "message": "Device registered successfully"
}
```

#### Code Example

```typescript
const registerDevice = async (data: {
  deviceId: string;
  fcmToken: string;
  platform: 'ios' | 'android';
  timezone?: string;
  displayName?: string;
}) => {
  const res = await fetch(
    `${API_BASE}/register-device`,
    {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${await getIdToken()}` // Required!
      },
      body: JSON.stringify(data),
    }
  );
  return res.json(); // { success, message }
};
```

#### User Journey

1. **Fresh Install:** App calls `auth().signInAnonymously()` ‚Üí Gets `uid` ‚Üí Registers device with token
2. **Device Ownership:** The device document stores `uid`, linking the device to the user
3. **Account Link (Gmail):** Same `uid` persists after linking; device remains associated
4. **Reinstall:** New anonymous `uid` is created; device ownership transfers to new account
5. **Recovery:** User signs in with Google ‚Üí Original `uid` restored ‚Üí Device re-linked

---

### 9. Event Tracking

Tracks user behavioral events with idempotent writes and automatic streak computation.

> **Auth Required:** Yes  
> **Method:** `POST`

```http
POST /events
Authorization: Bearer <token>
Content-Type: application/json
```

#### Request Body

```json
{
  "eventId": "550e8400-e29b-41d4-a716-446655440000",
  "eventName": "WEIGHT_LOGGED",
  "timestamp": "2026-01-24T14:30:00.000Z",
  "timezone": "Asia/Kolkata",
  "sessionId": "660e8400-e29b-41d4-a716-446655440001",
  "platform": "ios",
  "metadata": {
    "weight_value": 72.5,
    "unit": "kg",
    "source": "manual"
  }
}
```

| Field | Type | Description |
|-------|------|-------------|
| `eventId` | UUID v4 | **Client-generated** unique ID for idempotency |
| `eventName` | enum | Event type (see below) |
| `timestamp` | ISO 8601 | When the user triggered the action |
| `timezone` | IANA string | User's timezone (e.g., `Asia/Kolkata`) |
| `sessionId` | UUID v4 | Session ID (generated on app launch) |
| `platform` | enum | `"ios"` or `"android"` |
| `metadata` | object | Event-specific data (varies by eventName) |

#### Event Types

| Event Name | Description | Metadata Fields |
|------------|-------------|-----------------|
| `WEIGHT_LOGGED` | User logged weight | `weight_value`, `unit`, `source` |
| `FOOD_ANALYZED` | Food image analyzed | `success`, `food_detected`, `credits_remaining`, `latency_ms` |
| `DEVICE_REGISTERED` | Device registered | `timezone`, `platform`, `app_version?` |
| `NOTIFICATION_DELIVERED` | Push notification sent (server) | `notification_id`, `notification_type`, `delivery_status` |
| `NOTIFICATION_RECEIVED` | Notification received on device | `notification_id`, `received_at` |
| `NOTIFICATION_OPENED` | User opened notification | `notification_id`, `opened_at` |
| `INTENT_CAPTURED` | User created an intent | `intent_type`, `expected_duration` |
| `INTENT_CLOSED` | Intent was closed | `intent_type`, `outcome`, `actual_duration`, `expected_duration` |

#### Metadata Schemas

**WEIGHT_LOGGED:**
```json
{
  "weight_value": 72.5,
  "unit": "kg",
  "source": "manual"
}
```

| Field | Type | Constraints |
|-------|------|-------------|
| `weight_value` | number | positive |
| `unit` | enum | `"kg"` or `"lbs"` (default: `"kg"`) |
| `source` | enum | `"manual"` or `"auto"` (default: `"manual"`) |

**INTENT_CAPTURED:**
```json
{
  "intent_type": "workout",
  "expected_duration": 30
}
```

| Field | Type | Constraints |
|-------|------|-------------|
| `intent_type` | string | min 1 char |
| `expected_duration` | number | minutes (int >= 0) |

**INTENT_CLOSED:**
```json
{
  "intent_type": "workout",
  "outcome": "completed",
  "actual_duration": 28,
  "expected_duration": 30
}
```

| Field | Type | Constraints |
|-------|------|-------------|
| `intent_type` | string | min 1 char |
| `outcome` | enum | `"completed"`, `"abandoned"`, `"expired"` |
| `actual_duration` | number | minutes (int >= 0) |
| `expected_duration` | number | minutes (int >= 0) |

#### Response

```json
{
  "success": true,
  "status": "created",
  "eventId": "550e8400-e29b-41d4-a716-446655440000"
}
```

| Field | Type | Description |
|-------|------|-------------|
| `status` | enum | `"created"` (new event) or `"duplicate"` (already exists) |

> [!NOTE]
> Returns 200 OK for **both** new and duplicate events (idempotent success).

#### Streak Logic

When `WEIGHT_LOGGED` events are received, the backend automatically computes streaks:

| Condition | Action |
|-----------|--------|
| First log ever | `streak = 1` |
| Same day as last log | `streak` unchanged |
| Consecutive day | `streak++` |
| Gap > 1 day | `streak = 1` (reset) |

Streak state is stored on the user document and updated transactionally.

#### Code Example

```typescript
const trackEvent = async (
  eventName: string,
  metadata: Record<string, unknown>
) => {
  const response = await fetch(
    `${API_BASE}/events`,
    {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${await getIdToken()}`
      },
      body: JSON.stringify({
        eventId: crypto.randomUUID(),
        eventName,
        timestamp: new Date().toISOString(),
        timezone: Intl.DateTimeFormat().resolvedOptions().timeZone,
        sessionId: getSessionId(), // App-maintained session
        platform: Platform.OS, // 'ios' or 'android'
        metadata,
      }),
    }
  );
  return response.json();
};

// Example: Log weight
await trackEvent('WEIGHT_LOGGED', {
  weight_value: 72.5,
  unit: 'kg',
  source: 'manual',
});

// Example: Intent captured (in handleAddIntent)
await trackEvent('INTENT_CAPTURED', {
  intent_type: intent.type,
  expected_duration: intent.expected_duration,
});

// Example: Intent closed (on closure)
await trackEvent('INTENT_CLOSED', {
  intent_type: closedIntent.type,
  outcome: 'completed', // or 'abandoned' or 'expired'
  actual_duration: closedIntent.actual_duration,
  expected_duration: closedIntent.expected_duration,
});

// Example: Notification opened (in push notification handler)
// The notification_id is automatically included in the FCM data payload
await trackEvent('NOTIFICATION_OPENED', {
  notification_id: notification.data.notification_id, // Provided by backend
  opened_at: new Date().toISOString(),
});

// Example: Notification received (in push handler)
await trackEvent('NOTIFICATION_RECEIVED', {
  notification_id: notification.data.notification_id,
  received_at: new Date().toISOString(),
});
```

> [!NOTE]
> **Notification ID Tracking:** All push notifications sent by the backend include a `notification_id` field in the FCM data payload. Use this ID when tracking `NOTIFICATION_RECEIVED` and `NOTIFICATION_OPENED` events to correlate user engagement with specific notifications.

#### Client Requirements

1. **UUID Generation:** Client must generate `eventId` using UUID v4
2. **Session Management:**
   - Generate `sessionId` on App Launch
   - Persist in memory until app kill or >30min background
3. **Timezone:** Send `Intl.DateTimeFormat().resolvedOptions().timeZone`
4. **Offline Handling:** Queue events locally and retry on network restore

---

## Error Codes

| Code | HTTP | Description |
|------|------|-------------|
| `UNAUTHORIZED` | 401 | Missing, invalid, or expired token |
| `INSUFFICIENT_CREDITS` | 402 | No credits remaining |
| `INVALID_REQUEST` | 400 | Malformed request or missing required fields |
| `NOT_FOOD` | 422 | Image does not contain recognizable food |
| `IMAGE_TOO_BLURRY` | 422 | Image too blurry for analysis |
| `LOW_CONFIDENCE` | 422 | Cannot confidently identify the food. Returned when *any* detected item cannot be identified with sufficient confidence (in multi-item images, one ambiguous item triggers this). |
| `MULTIPLE_FOODS` | 422 | *Deprecated* ‚Äî now handled automatically |
| `IMAGE_TOO_LARGE` | 413 | Image exceeds 5MB limit |
| `UNSUPPORTED_FORMAT` | 415 | Invalid image format |
| `PARSE_ERROR` | 500 | AI returned invalid response |
| `AI_SERVICE_ERROR` | 503 | OpenAI API temporarily unavailable |
| `AI_CONFIG_ERROR` | 500 | Server misconfiguration |
| `BACKUP_NOT_FOUND` | 404 | No backup exists for user |
| `STORAGE_ERROR` | 500 | Cloud storage operation failed |
| `RATE_LIMITED` | 429 | Too many requests |
| `INTERNAL_ERROR` | 500 | Unexpected server error |

---

## Rate Limiting & Credits

### Credit System

| Event | Credits |
|-------|---------|
| New user registration | +20 (free) |
| Food image analysis | -1 |

When credits reach 0, `/analyze-food` returns:

```json
{
  "success": false,
  "error": "Insufficient AI credits",
  "code": "INSUFFICIENT_CREDITS"
}
```

### Best Practices

1. **Check credits before analysis** ‚Äî call `/credits` first
2. **Cache the profile** ‚Äî avoid excessive `/user/me` calls
3. **Handle 402 gracefully** ‚Äî show upgrade prompt in UI

---

## Internal Architecture (For Advanced Integrators)

> [!WARNING]
> The fields, thresholds, and behaviors in this section are **not part of the public API contract** and may change without notice. Do not build client-side logic that depends on internal implementation details.

### 2-Pass Vision Inference

The food analysis endpoint uses a sophisticated 2-pass system:

```
Image ‚Üí Pass 1 ‚Üí [Trigger Check] ‚Üí Pass 2 (if needed) ‚Üí Agreement Logic ‚Üí Result
```

#### When Pass 2 Is Triggered

| Condition | Threshold |
|-----------|-----------|
| Any item confidence | < 0.8 |
| Multiple items detected | > 1 item |
| Total estimated weight | ‚â• 200g |

#### Agreement Logic

If both passes run:

| Check | Threshold |
|-------|-----------|
| Calorie difference | ‚â§ 15% |
| Weight difference | ‚â§ 50g |
| Item matching | ‚â• 70% name similarity |

- **Agreed:** Values are averaged
- **Diverged:** Lower calorie result is selected

### Data Persistence

All analyses are stored in Firestore (`food_analyses` collection):

```typescript
{
  imageHash: string,          // SHA-256 + byte length salt
  imageByteLength: number,
  model: "gpt-5.2",
  promptVersion: "vision_v3_canonical_2pass",
  pass1RawText: string,       // Raw LLM output
  pass1Parsed: VisionPassResult,
  pass2RawText?: string,      // If Pass 2 ran
  pass2Parsed?: VisionPassResult,
  status: "SINGLE_PASS" | "TWO_PASS_AGREED" | "TWO_PASS_DIVERGED",
  divergenceReason?: "CALORIES" | "WEIGHT" | "ITEM_MISMATCH",
  finalResult: VisionPassResult,
  createdAt: Timestamp,
  durationMs: number
}
```

This enables:
- Variance analysis
- Prompt tuning
- Confidence calibration
- Regression detection

---

## Quick Start Example (TypeScript)

```typescript
import { initializeApp } from "firebase/app";
import { getAuth, signInAnonymously } from "firebase/auth";

const app = initializeApp({ /* your config */ });
const auth = getAuth(app);

const API_BASE = 'https://api-<deployment-hash>-uc.a.run.app';

async function analyzeFood(imageBase64: string) {
  const user = await signInAnonymously(auth);
  const token = await user.user.getIdToken();

  const response = await fetch(
    `${API_BASE}/analyze-food`,
    {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${token}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({ image: imageBase64 }),
    }
  );

  const result = await response.json();
  
  if (!result.success) {
    switch (result.code) {
      case "INSUFFICIENT_CREDITS":
        // Show upgrade prompt
        break;
      case "NOT_FOOD":
        // Show "please take a photo of food" message
        break;
      default:
        throw new Error(result.error);
    }
  }

  return result.nutrition;
}
```

---

## UI Copy Suggestions

Recommended user-facing messages for common errors:

| Error Code | Suggested UI Copy |
|------------|-------------------|
| `NOT_FOOD` | "We couldn't find any food in this photo. Try taking a picture of your meal." |
| `LOW_CONFIDENCE` | "We're not sure what this is. Try taking a clearer photo with better lighting." |
| `IMAGE_TOO_BLURRY` | "This photo is too blurry. Hold your phone steady and try again." |
| `INSUFFICIENT_CREDITS` | "You've used all your free analyses. Upgrade to continue tracking." |
| `AI_SERVICE_ERROR` | "Our servers are busy. Please try again in a moment." |

---

## 10. Workflows (Deferred Deep Links)

Server-authoritative workflow system for deferred deep linking. Enables campaigns, email links, and install referrer tracking.

### TypeScript Interfaces

```typescript
// Workflow types
type WorkflowType = "LOG_WEIGHT";
type WorkflowStatus = "ACTIVE" | "COMPLETED" | "EXPIRED";

interface LogWeightPayload {
  suggestedWeight?: number; // 20-300
  source?: string;
}

interface CreateWorkflowRequest {
  type: WorkflowType;
  payload?: LogWeightPayload;
  expiresInHours?: number; // Default: 48, Min: 1, Max: 72
  campaignId?: string;
  maxResolves?: number;
}

interface CreateWorkflowResponse {
  success: true;
  workflowId: string;
  deepLinkUrl: string;
}

interface ResolveWorkflowResponse {
  success: true;
  type: WorkflowType;
  status: WorkflowStatus;
  payload: LogWeightPayload;
  expiresAt: string; // ISO 8601
}

interface CompleteWorkflowResponse {
  success: true;
  status: "COMPLETED";
}
```

### Create Workflow

> **Auth Required:** Yes  
> **Method:** `POST`

```http
POST /workflows
Authorization: Bearer <token>
Content-Type: application/json

{
  "type": "LOG_WEIGHT",
  "payload": { "suggestedWeight": 72.5, "source": "email_campaign" },
  "expiresInHours": 48,
  "campaignId": "JAN_NUDGE"
}
```

**Response:**

```json
{
  "success": true,
  "workflowId": "WF_01HRX...",
  "deepLinkUrl": "https://platewise.app/wf/WF_01HRX..."
}
```

### Resolve Workflow

> **Auth Required:** No (public)  
> **Method:** `GET`

```http
GET /workflows/WF_01HRX...
```

**Response (ACTIVE):**

```json
{
  "success": true,
  "type": "LOG_WEIGHT",
  "status": "ACTIVE",
  "payload": { "suggestedWeight": 72.5 },
  "expiresAt": "2026-02-01T00:00:00.000Z"
}
```

**Response (EXPIRED):**

```json
{
  "success": true,
  "type": "LOG_WEIGHT",
  "status": "EXPIRED",
  "payload": { "suggestedWeight": 72.5 },
  "expiresAt": "2026-01-30T00:00:00.000Z"
}
```

### Complete Workflow

> **Auth Required:** No (public)  
> **Method:** `POST`

```http
POST /workflows/WF_01HRX.../complete
```

**Response:**

```json
{
  "success": true,
  "status": "COMPLETED"
}
```

> [!NOTE]
> Completion is **idempotent** ‚Äî calling on already-completed workflows returns success.

### Error Codes

| Code | HTTP | Description |
|------|------|-------------|
| `INVALID_WORKFLOW_ID` | 400 | Malformed workflow ID format |
| `INVALID_WORKFLOW_TYPE` | 400 | Unknown workflow type |
| `INVALID_TTL` | 400 | TTL outside 1-72 hour range |
| `INVALID_PAYLOAD` | 400 | Payload validation failed |
| `WORKFLOW_NOT_FOUND` | 404 | Workflow does not exist |
| `WORKFLOW_EXPIRED` | 409 | Cannot complete expired workflow |

---

## Frontend Integration: Vercel Route Handler

Create `/wf/[workflowId]/route.ts` in your Next.js app:

```typescript
// app/wf/[workflowId]/route.ts
import { NextRequest, NextResponse } from "next/server";

const PLAY_STORE_URL = "https://play.google.com/store/apps/details";
const APP_STORE_URL = "https://apps.apple.com/app/idYOUR_APP_ID";
const PACKAGE_NAME = "com.yourapp.package";

export async function GET(
  request: NextRequest,
  { params }: { params: { workflowId: string } }
) {
  const { workflowId } = params;
  
  // Validate workflow ID format (prevent injection)
  if (!/^WF_[0-9A-HJKMNP-TV-Z]{26}$/.test(workflowId)) {
    return NextResponse.redirect(new URL("/", request.url));
  }
  
  const userAgent = request.headers.get("user-agent") || "";
  
  // Detect platform
  const isAndroid = /android/i.test(userAgent);
  const isIOS = /iphone|ipad|ipod/i.test(userAgent);
  
  if (isAndroid) {
    // Redirect to Play Store with install referrer
    const referrer = encodeURIComponent(`workflow_id=${workflowId}`);
    const playUrl = `${PLAY_STORE_URL}?id=${PACKAGE_NAME}&referrer=${referrer}`;
    return NextResponse.redirect(playUrl);
  }
  
  if (isIOS) {
    // Redirect to App Store (no native referrer support)
    return NextResponse.redirect(APP_STORE_URL);
  }
  
  // Desktop: Show fallback page with QR code
  return NextResponse.redirect(new URL(`/download?wf=${workflowId}`, request.url));
}
```

---

## Frontend Integration: Android Install Referrer

After app install, extract workflow ID from Play Store referrer:

```kotlin
// Android - Using Play Install Referrer SDK
// Add dependency: com.android.installreferrer:installreferrer:2.2

class InstallReferrerHelper(private val context: Context) {
    private lateinit var referrerClient: InstallReferrerClient

    fun getWorkflowId(callback: (String?) -> Unit) {
        referrerClient = InstallReferrerClient.newBuilder(context).build()
        
        referrerClient.startConnection(object : InstallReferrerStateListener {
            override fun onInstallReferrerSetupFinished(responseCode: Int) {
                if (responseCode == InstallReferrerClient.OK) {
                    try {
                        val referrer = referrerClient.installReferrer.installReferrer
                        val workflowId = extractWorkflowId(referrer)
                        callback(workflowId)
                    } catch (e: Exception) {
                        callback(null)
                    }
                    referrerClient.endConnection()
                }
            }
            
            override fun onInstallReferrerServiceDisconnected() {
                callback(null)
            }
        })
    }
    
    private fun extractWorkflowId(referrer: String): String? {
        // Parse: workflow_id=WF_01HRX...
        val regex = "workflow_id=(WF_[0-9A-HJKMNP-TV-Z]{26})".toRegex()
        return regex.find(referrer)?.groupValues?.get(1)
    }
}

// Usage on first app launch:
InstallReferrerHelper(context).getWorkflowId { workflowId ->
    if (workflowId != null) {
        // Call backend: GET /workflows/{workflowId}
        resolveWorkflow(workflowId) { response ->
            when (response.status) {
                "ACTIVE" -> navigateToWeightEntry(response.payload.suggestedWeight)
                "COMPLETED" -> navigateToTrends()
                "EXPIRED" -> navigateToHome()
            }
        }
    }
}
```

---

## Workflow Resolution Flow

```mermaid
sequenceDiagram
    participant User
    participant Email/SMS
    participant Vercel
    participant PlayStore
    participant App
    participant Backend

    Email/SMS->>User: Click link (platewise.app/wf/WF_123)
    User->>Vercel: GET /wf/WF_123
    Vercel->>PlayStore: Redirect with referrer
    PlayStore->>User: Install app
    User->>App: Launch app
    App->>App: Read install referrer
    App->>Backend: GET /workflows/WF_123
    Backend->>App: {status: ACTIVE, payload: {...}}
    App->>User: Navigate to weight entry
    App->>Backend: POST /workflows/WF_123/complete
```

> [!IMPORTANT]
> **Backend does NOT validate install source.** Install attribution is a frontend-only concern. Resolution is allowed from any source ‚Äî this is by design.

---

## Support

For issues or questions, contact the backend team or file an issue in the repository.
</file>

</files>
